{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10619761,"sourceType":"datasetVersion","datasetId":6575330},{"sourceId":10634703,"sourceType":"datasetVersion","datasetId":6584359}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Step 1: Load the Data\ndata = pd.read_csv('/kaggle/input/main-dataset/Sampling_data.csv')\n\n# Step 2: Data Preprocessing\n# Fill missing values in the relevant columns\ndata['review'].fillna('No review', inplace=True)\ndata['usefulCount'].fillna(0, inplace=True)\n\n# Label encode the 'Drug Name' and 'Condition' columns\nle = LabelEncoder()\ndata['Drug Name'] = le.fit_transform(data['Drug Name'])\ndata['condition'] = le.fit_transform(data['condition'])\n\n# Step 3: Text Vectorization (For 'Review' column)\ntfidf = TfidfVectorizer(max_features=5000)\nreview_features = tfidf.fit_transform(data['review']).toarray()\n\n# Step 4: Prepare Data for Training\n# Combine the features and target\nX = pd.concat([data[['Drug Name', 'condition', 'usefulCount']], pd.DataFrame(review_features)], axis=1)\ny = data['rating']\n\n# Step 5: Train-Test Split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Step 6: LightGBM Model Training\ntrain_data = lgb.Dataset(X_train, label=y_train)\ntest_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n\n# Define model parameters\nparams = {\n    'objective': 'regression',\n    'metric': 'rmse',\n    'boosting_type': 'gbdt',\n    'num_leaves': 31,\n    'learning_rate': 0.05,\n    'feature_fraction': 0.9\n}\n\n# Train the model with early stopping using a callback\ncallbacks = [lgb.early_stopping(stopping_rounds=100)]\nmodel = lgb.train(params, train_data, num_boost_round=1000, valid_sets=[test_data], callbacks=callbacks)\n\n# Step 7: Make Predictions\ny_pred = model.predict(X_test, num_iteration=model.best_iteration)\n\n# Step 8: Evaluate the Model\nmse = mean_squared_error(y_test, y_pred)  # Compute Mean Squared Error\nrmse = np.sqrt(mse)  # Compute Root Mean Squared Error (RMSE)\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\n\n# Step 9: Compare Actual vs Predicted Ratings\nresults = pd.DataFrame({'Actual Rating': y_test, 'Predicted Rating': y_pred})\nprint(results.head())\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-30T19:31:01.429506Z","iopub.execute_input":"2025-01-30T19:31:01.429808Z","iopub.status.idle":"2025-01-30T19:33:12.637211Z","shell.execute_reply.started":"2025-01-30T19:31:01.429782Z","shell.execute_reply":"2025-01-30T19:33:12.636375Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-5-6a272e2e6260>:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  data['review'].fillna('No review', inplace=True)\n<ipython-input-5-6a272e2e6260>:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  data['usefulCount'].fillna(0, inplace=True)\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.343582 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 386806\n[LightGBM] [Info] Number of data points in the train set: 63056, number of used features: 5001\n[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n[LightGBM] [Info] Start training from score 7.120464\nTraining until validation scores don't improve for 100 rounds\nDid not meet early stopping. Best iteration is:\n[1000]\tvalid_0's rmse: 2.13249\nRoot Mean Squared Error (RMSE): 2.132494380655219\n       Actual Rating  Predicted Rating\n29406              5          6.051184\n71698              7          5.718252\n56929              9          7.783373\n75201              7          7.503216\n49098              8          6.456917\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Step 1: Load the Data\ndata = pd.read_csv('/kaggle/input/main-dataset/Sampling_data.csv')\n\n# Step 2: Data Preprocessing\n# Handle missing values\ndata['review'].fillna('No review', inplace=True)\ndata['usefulCount'].fillna(0, inplace=True)\n\n# Label encoding for categorical features\nle = LabelEncoder()\ndata['Drug Name'] = le.fit_transform(data['Drug Name'])\ndata['condition'] = le.fit_transform(data['condition'])\n\n# Step 3: Advanced Text Vectorization (TF-IDF with n-grams)\ntfidf = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))  # Capture more context\nreview_features = tfidf.fit_transform(data['review']).toarray()\n\n# Step 4: Prepare Training Data\nX = pd.concat([data[['Drug Name', 'condition', 'usefulCount']], pd.DataFrame(review_features)], axis=1)\ny = data['rating']\n\n# Step 5: Train-Test Split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Step 6: LightGBM Model Training\ntrain_data = lgb.Dataset(X_train, label=y_train)\ntest_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n\n# Optimized Model Parameters\nparams = {\n    'objective': 'regression',\n    'metric': 'rmse',\n    'boosting_type': 'gbdt',\n    'num_leaves': 50,  # Increased complexity\n    'max_depth': 10,   # Deeper trees for better learning\n    'learning_rate': 0.03,  # Slightly slower but improves accuracy\n    'feature_fraction': 0.8,  # Helps generalization\n    'bagging_fraction': 0.9,\n    'bagging_freq': 5,\n    'lambda_l1': 0.1,  # L1 regularization\n    'lambda_l2': 0.1,  # L2 regularization\n    'min_data_in_leaf': 20,  # Avoids overfitting\n    'verbosity': -1\n}\n\n# Train the model with early stopping\ncallbacks = [lgb.early_stopping(stopping_rounds=100)]\nmodel = lgb.train(params, train_data, num_boost_round=2000, valid_sets=[test_data], callbacks=callbacks)\n\n# Step 7: Make Predictions\ny_pred = model.predict(X_test, num_iteration=model.best_iteration)\n\n# Step 8: Evaluate the Model\nmse = mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(mse)\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\n\n# Step 9: Compare Actual vs Predicted Ratings\nresults = pd.DataFrame({'Actual Rating': y_test, 'Predicted Rating': np.round(y_pred)})\nprint(results.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T19:35:31.525585Z","iopub.execute_input":"2025-01-30T19:35:31.525976Z","iopub.status.idle":"2025-01-30T19:46:09.632059Z","shell.execute_reply.started":"2025-01-30T19:35:31.525947Z","shell.execute_reply":"2025-01-30T19:46:09.631022Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-6-520480f567c0>:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  data['review'].fillna('No review', inplace=True)\n<ipython-input-6-520480f567c0>:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  data['usefulCount'].fillna(0, inplace=True)\n","output_type":"stream"},{"name":"stdout","text":"Training until validation scores don't improve for 100 rounds\nDid not meet early stopping. Best iteration is:\n[2000]\tvalid_0's rmse: 2.04561\nRoot Mean Squared Error (RMSE): 2.0456090522837886\n       Actual Rating  Predicted Rating\n29406              5               4.0\n71698              7               7.0\n56929              9               8.0\n75201              7               8.0\n49098              8               8.0\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"\n\n\nimport pandas as pd\nimport lightgbm as lgb\nimport xgboost as xgb\nimport catboost as cb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.ensemble import StackingRegressor\n\n# Step 1: Load Data\ndata = pd.read_csv('/kaggle/input/main-dataset/Sampling_data.csv')\n\n# Step 2: Data Preprocessing\ndata['review'].fillna('No review', inplace=True)\ndata['usefulCount'].fillna(0, inplace=True)\n\n# Label Encoding\nle = LabelEncoder()\ndata['Drug Name'] = le.fit_transform(data['Drug Name'])\ndata['condition'] = le.fit_transform(data['condition'])\n\n# Step 3: Feature Engineering (TF-IDF + Dimensionality Reduction)\ntfidf = TfidfVectorizer(max_features=20000, ngram_range=(1, 2))\nreview_features = tfidf.fit_transform(data['review'])\n\n# Reduce dimensions for speed\nsvd = TruncatedSVD(n_components=50, random_state=42)\nreview_features = svd.fit_transform(review_features)\n\n# Combine Features\nX = np.hstack((data[['Drug Name', 'condition', 'usefulCount']].values, review_features))\ny = data['rating']\n\n# Train-Test Split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Step 4: Model Setup (Stacking for Higher Accuracy)\nlgbm = lgb.LGBMRegressor(num_leaves=60, max_depth=12, learning_rate=0.02, n_estimators=1000)\nxgb_model = xgb.XGBRegressor(learning_rate=0.02, max_depth=10, n_estimators=1000)\ncat_model = cb.CatBoostRegressor(depth=10, learning_rate=0.02, iterations=1000, verbose=0)\n\n# Stacking Model\nstack = StackingRegressor(estimators=[('lgbm', lgbm), ('xgb', xgb_model), ('cat', cat_model)], final_estimator=lgb.LGBMRegressor())\n\n# Train Model\nstack.fit(X_train, y_train)\n\n# Predict\ny_pred = stack.predict(X_test)\n\n# Step 5: Evaluate\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nprint(f\"ðŸš€ Root Mean Squared Error (RMSE): {rmse:.4f}\")\n\n# Show Actual vs Predicted\nresults = pd.DataFrame({'Actual': y_test, 'Predicted': np.round(y_pred)})\nprint(results.head(10))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T19:48:07.845373Z","iopub.execute_input":"2025-01-30T19:48:07.845765Z","iopub.status.idle":"2025-01-30T20:08:53.078509Z","shell.execute_reply.started":"2025-01-30T19:48:07.845739Z","shell.execute_reply":"2025-01-30T20:08:53.077803Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-7-b7202864e397>:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  data['review'].fillna('No review', inplace=True)\n<ipython-input-7-b7202864e397>:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  data['usefulCount'].fillna(0, inplace=True)\n","output_type":"stream"},{"name":"stdout","text":"ðŸš€ Root Mean Squared Error (RMSE): 2.1223\n       Actual  Predicted\n29406       5        4.0\n71698       7        9.0\n56929       9       10.0\n75201       7        8.0\n49098       8        7.0\n22663      10        8.0\n41681       9        8.0\n21189       7        7.0\n47791       9        9.0\n78480      10        9.0\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport xgboost as xgb\nimport optuna\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler\n\n# Load Data\ndata = pd.read_csv('/kaggle/input/main-dataset/Sampling_data.csv')\n\n# Convert to DataFrame\ndf = pd.DataFrame(data)\n\n# Convert categorical columns to numeric (if not already)\ndf['Drug Name'] = df['Drug Name'].astype('category').cat.codes\ndf['condition'] = df['condition'].astype('category').cat.codes\n\n# Step 1: Handle the 'review' column using TF-IDF vectorizer\ntfidf = TfidfVectorizer(stop_words='english', max_features=200)\nreview_features = tfidf.fit_transform(df['review']).toarray()\n\n# Convert the review features to a DataFrame\nreview_df = pd.DataFrame(review_features, columns=tfidf.get_feature_names_out())\n\n# Combine the review features with other features\ndf = pd.concat([df, review_df], axis=1)\n\n# Drop the original 'review' column\ndf.drop(columns=['review'], inplace=True)\n\n# Features and target\nfeatures = ['Drug Name', 'condition', 'usefulCount'] + list(review_df.columns)\ntarget = 'rating'\n\n# Step 2: Split data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=42)\n\n# Feature Scaling\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Step 3: Hyperparameter tuning with Optuna\ndef objective(trial):\n    params = {\n        'objective': 'reg:squarederror',\n        'eval_metric': 'rmse',\n        'max_depth': trial.suggest_int('max_depth', 3, 10),\n        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n        'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n        'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n        'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n        'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n    }\n    \n    model = xgb.XGBRegressor(**params)\n    model.fit(X_train_scaled, y_train)\n    y_pred = model.predict(X_test_scaled)\n    \n    # Calculate RMSE manually\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    \n    return rmse\n\n# Create Optuna study to minimize RMSE\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=50)\n\n# Get best parameters from Optuna study\nbest_params = study.best_params\nprint(\"Best Parameters:\", best_params)\n\n# Step 4: Train final model using the best parameters\nfinal_model = xgb.XGBRegressor(**best_params)\nfinal_model.fit(X_train_scaled, y_train)\n\n# Step 5: Make predictions and evaluate RMSE\ny_pred = final_model.predict(X_test_scaled)\n\n# Calculate RMSE manually\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nprint(f\"Final RMSE: {rmse}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T20:15:17.448499Z","iopub.execute_input":"2025-01-30T20:15:17.448822Z","iopub.status.idle":"2025-01-30T21:10:04.411873Z","shell.execute_reply.started":"2025-01-30T20:15:17.448795Z","shell.execute_reply":"2025-01-30T21:10:04.411019Z"}},"outputs":[{"name":"stderr","text":"[I 2025-01-30 20:15:25,509] A new study created in memory with name: no-name-7663aa78-0830-4a00-9e9d-ad65ead10adc\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:15:34,012] Trial 0 finished with value: 2.7731123627762546 and parameters: {'max_depth': 6, 'learning_rate': 0.023168864143409854, 'n_estimators': 127, 'subsample': 0.7559971724638109, 'colsample_bytree': 0.8710458700422359, 'gamma': 4.907628220098289e-05, 'lambda': 9.99205368572354e-07, 'alpha': 4.103861512051956e-05}. Best is trial 0 with value: 2.7731123627762546.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:16:00,662] Trial 1 finished with value: 2.578217131182308 and parameters: {'max_depth': 3, 'learning_rate': 0.06322290098646736, 'n_estimators': 942, 'subsample': 0.7989821181034893, 'colsample_bytree': 0.6466045024507235, 'gamma': 0.8529348762016343, 'lambda': 0.21531304668177473, 'alpha': 0.00024258754572523963}. Best is trial 1 with value: 2.578217131182308.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:16:16,128] Trial 2 finished with value: 2.819074047623469 and parameters: {'max_depth': 3, 'learning_rate': 0.010313900473790577, 'n_estimators': 490, 'subsample': 0.729745432270674, 'colsample_bytree': 0.9725262122103511, 'gamma': 1.648420585233787e-08, 'lambda': 0.00020794264845410318, 'alpha': 0.0099725814600949}. Best is trial 1 with value: 2.578217131182308.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:17:14,354] Trial 3 finished with value: 2.3365626668293746 and parameters: {'max_depth': 8, 'learning_rate': 0.1527760110741857, 'n_estimators': 785, 'subsample': 0.8399879456564991, 'colsample_bytree': 0.9826689732621716, 'gamma': 0.05347288156231101, 'lambda': 3.977661191921972e-06, 'alpha': 3.414148246130684e-06}. Best is trial 3 with value: 2.3365626668293746.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:17:45,204] Trial 4 finished with value: 2.5466230912680343 and parameters: {'max_depth': 7, 'learning_rate': 0.027410682613368886, 'n_estimators': 466, 'subsample': 0.6887539900041054, 'colsample_bytree': 0.7149650221142461, 'gamma': 0.006880394485822921, 'lambda': 1.4890174926910087e-07, 'alpha': 0.050846199685309255}. Best is trial 3 with value: 2.3365626668293746.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:18:15,654] Trial 5 finished with value: 2.477524894629959 and parameters: {'max_depth': 5, 'learning_rate': 0.09818324113541002, 'n_estimators': 810, 'subsample': 0.6941917583300089, 'colsample_bytree': 0.8078077582727591, 'gamma': 6.033594054064009e-05, 'lambda': 1.0453545198997983e-08, 'alpha': 0.004550941867864595}. Best is trial 3 with value: 2.3365626668293746.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:18:27,623] Trial 6 finished with value: 2.6306186711831248 and parameters: {'max_depth': 4, 'learning_rate': 0.056639933881146506, 'n_estimators': 310, 'subsample': 0.7896575899941136, 'colsample_bytree': 0.9070419567499253, 'gamma': 1.2421576387709697e-07, 'lambda': 0.05645820156388533, 'alpha': 0.005230116104711788}. Best is trial 3 with value: 2.3365626668293746.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:18:50,526] Trial 7 finished with value: 2.6378669091770988 and parameters: {'max_depth': 7, 'learning_rate': 0.01979009706243815, 'n_estimators': 295, 'subsample': 0.8241796340515, 'colsample_bytree': 0.8164099411773205, 'gamma': 0.12877240514036686, 'lambda': 0.16756418468665654, 'alpha': 0.01830301948364695}. Best is trial 3 with value: 2.3365626668293746.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:19:06,138] Trial 8 finished with value: 2.602109787109399 and parameters: {'max_depth': 3, 'learning_rate': 0.08065142928892516, 'n_estimators': 532, 'subsample': 0.663318718203228, 'colsample_bytree': 0.7090726276852763, 'gamma': 4.841506744806362e-07, 'lambda': 0.2736564610346513, 'alpha': 6.70310291763973e-05}. Best is trial 3 with value: 2.3365626668293746.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:19:28,298] Trial 9 finished with value: 2.4793893983096416 and parameters: {'max_depth': 5, 'learning_rate': 0.12160130735230987, 'n_estimators': 621, 'subsample': 0.9829820343667689, 'colsample_bytree': 0.7778364242052591, 'gamma': 8.99544256404777e-08, 'lambda': 6.354677174289049e-05, 'alpha': 0.011149821562030563}. Best is trial 3 with value: 2.3365626668293746.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:20:50,303] Trial 10 finished with value: 2.377404587355061 and parameters: {'max_depth': 10, 'learning_rate': 0.29023354144747, 'n_estimators': 744, 'subsample': 0.8970111569839523, 'colsample_bytree': 0.9995818084840635, 'gamma': 0.014470410024855258, 'lambda': 1.078682495368932e-05, 'alpha': 2.4392651478458336e-08}. Best is trial 3 with value: 2.3365626668293746.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:22:11,382] Trial 11 finished with value: 2.3530668424207324 and parameters: {'max_depth': 10, 'learning_rate': 0.29712518401835714, 'n_estimators': 749, 'subsample': 0.9137961862479499, 'colsample_bytree': 0.9789894855732201, 'gamma': 0.0078827034382152, 'lambda': 7.4913093207207536e-06, 'alpha': 2.9567412520702954e-08}. Best is trial 3 with value: 2.3365626668293746.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:23:56,599] Trial 12 finished with value: 2.340341312495045 and parameters: {'max_depth': 10, 'learning_rate': 0.2555572004681055, 'n_estimators': 983, 'subsample': 0.8902906621809384, 'colsample_bytree': 0.9319737396370961, 'gamma': 0.0016006708707172876, 'lambda': 0.0035249865428626094, 'alpha': 5.955847567672272e-08}. Best is trial 3 with value: 2.3365626668293746.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:25:23,027] Trial 13 finished with value: 2.3001665566515066 and parameters: {'max_depth': 9, 'learning_rate': 0.1525253494959776, 'n_estimators': 994, 'subsample': 0.8741877752411366, 'colsample_bytree': 0.8930662574595047, 'gamma': 0.000727059505758566, 'lambda': 0.0036137077621062295, 'alpha': 1.1041904548963528e-06}. Best is trial 13 with value: 2.3001665566515066.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:26:26,449] Trial 14 finished with value: 2.334608825468369 and parameters: {'max_depth': 8, 'learning_rate': 0.1552219551461289, 'n_estimators': 889, 'subsample': 0.8551180234485433, 'colsample_bytree': 0.8775052505185297, 'gamma': 0.0003673378995664198, 'lambda': 0.0018866700116322837, 'alpha': 3.743965060737992e-06}. Best is trial 13 with value: 2.3001665566515066.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:27:29,784] Trial 15 finished with value: 2.308938425822976 and parameters: {'max_depth': 8, 'learning_rate': 0.19207944227243967, 'n_estimators': 887, 'subsample': 0.9647248547219077, 'colsample_bytree': 0.8656107648636743, 'gamma': 6.00838361240538e-06, 'lambda': 0.00501762359729882, 'alpha': 3.1091016289415556}. Best is trial 13 with value: 2.3001665566515066.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:28:26,466] Trial 16 finished with value: 2.2986793172946305 and parameters: {'max_depth': 9, 'learning_rate': 0.1866880056645371, 'n_estimators': 641, 'subsample': 0.9927317358619651, 'colsample_bytree': 0.8518023827910908, 'gamma': 3.3345430467610935e-06, 'lambda': 0.004796205972061216, 'alpha': 4.217922697032018}. Best is trial 16 with value: 2.2986793172946305.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:29:35,534] Trial 17 finished with value: 2.422783135645317 and parameters: {'max_depth': 9, 'learning_rate': 0.03694330901466662, 'n_estimators': 654, 'subsample': 0.9413560133570427, 'colsample_bytree': 0.7731908906064877, 'gamma': 4.9229550494677545e-06, 'lambda': 7.645010148564501, 'alpha': 4.03699970805573}. Best is trial 16 with value: 2.2986793172946305.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:30:10,249] Trial 18 finished with value: 2.393107152811163 and parameters: {'max_depth': 9, 'learning_rate': 0.18469129696899972, 'n_estimators': 376, 'subsample': 0.6096482087367083, 'colsample_bytree': 0.8329216570821366, 'gamma': 4.544454158387359e-06, 'lambda': 7.832158596078039, 'alpha': 5.528614252854203e-07}. Best is trial 16 with value: 2.2986793172946305.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:31:03,369] Trial 19 finished with value: 2.3591971990115503 and parameters: {'max_depth': 9, 'learning_rate': 0.10239210028051278, 'n_estimators': 631, 'subsample': 0.9960204694595075, 'colsample_bytree': 0.9312007375530696, 'gamma': 0.000599376981804326, 'lambda': 0.01639729178843513, 'alpha': 0.34848951580531545}. Best is trial 16 with value: 2.2986793172946305.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:31:28,400] Trial 20 finished with value: 2.543874034536767 and parameters: {'max_depth': 9, 'learning_rate': 0.03772800266817217, 'n_estimators': 189, 'subsample': 0.9414392960899911, 'colsample_bytree': 0.748891229957923, 'gamma': 1.9562066622649245e-05, 'lambda': 0.0009021793336338587, 'alpha': 6.206791219395153e-06}. Best is trial 16 with value: 2.2986793172946305.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:32:36,422] Trial 21 finished with value: 2.2898725513943514 and parameters: {'max_depth': 8, 'learning_rate': 0.2044860301048244, 'n_estimators': 882, 'subsample': 0.9644884264667566, 'colsample_bytree': 0.8613377014725982, 'gamma': 4.788026734397807e-06, 'lambda': 0.013498905524204546, 'alpha': 6.640007654600243}. Best is trial 21 with value: 2.2898725513943514.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:33:33,230] Trial 22 finished with value: 2.319161574508773 and parameters: {'max_depth': 8, 'learning_rate': 0.2127977774415703, 'n_estimators': 859, 'subsample': 0.939577671379842, 'colsample_bytree': 0.8580588660973201, 'gamma': 1.1256115642955653e-06, 'lambda': 0.00019373659552453015, 'alpha': 0.4492764947899323}. Best is trial 21 with value: 2.2898725513943514.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:34:27,478] Trial 23 finished with value: 2.357903364362995 and parameters: {'max_depth': 7, 'learning_rate': 0.13662890890990623, 'n_estimators': 980, 'subsample': 0.8873266177643989, 'colsample_bytree': 0.9060906418091522, 'gamma': 0.00017724055266286903, 'lambda': 0.019963111112889814, 'alpha': 0.4338243886880342}. Best is trial 21 with value: 2.2898725513943514.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:35:37,268] Trial 24 finished with value: 2.3236953642471088 and parameters: {'max_depth': 9, 'learning_rate': 0.08139586545745424, 'n_estimators': 697, 'subsample': 0.9995589470849194, 'colsample_bytree': 0.8371153978026471, 'gamma': 9.243792080936266e-07, 'lambda': 0.9949978863464335, 'alpha': 9.266357335955696}. Best is trial 21 with value: 2.2898725513943514.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:36:37,701] Trial 25 finished with value: 2.3447569722890913 and parameters: {'max_depth': 8, 'learning_rate': 0.21698854575787885, 'n_estimators': 858, 'subsample': 0.8651248921709082, 'colsample_bytree': 0.903292108993722, 'gamma': 1.6058233985282472e-05, 'lambda': 0.013144238889608055, 'alpha': 0.001151143542722184}. Best is trial 21 with value: 2.2898725513943514.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:38:08,910] Trial 26 finished with value: 2.284621149519712 and parameters: {'max_depth': 10, 'learning_rate': 0.13027315094282185, 'n_estimators': 934, 'subsample': 0.9654417053527505, 'colsample_bytree': 0.940508302743128, 'gamma': 0.0015818835102586965, 'lambda': 4.8251169316153636e-05, 'alpha': 0.15418206822546598}. Best is trial 26 with value: 2.284621149519712.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:39:09,867] Trial 27 finished with value: 2.322052543782228 and parameters: {'max_depth': 10, 'learning_rate': 0.10606037246753004, 'n_estimators': 582, 'subsample': 0.9619532420400811, 'colsample_bytree': 0.9421690047482001, 'gamma': 0.002192052570974435, 'lambda': 4.3283038842650354e-05, 'alpha': 1.1283536817044684}. Best is trial 26 with value: 2.284621149519712.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:40:11,134] Trial 28 finished with value: 2.3195619725278056 and parameters: {'max_depth': 10, 'learning_rate': 0.0767771435320573, 'n_estimators': 691, 'subsample': 0.9202080599567881, 'colsample_bytree': 0.604165089118748, 'gamma': 0.00010949047164603238, 'lambda': 0.0005780684465797331, 'alpha': 0.10111872683284266}. Best is trial 26 with value: 2.284621149519712.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:40:52,654] Trial 29 finished with value: 2.360675993580841 and parameters: {'max_depth': 6, 'learning_rate': 0.2358013280701247, 'n_estimators': 821, 'subsample': 0.9654121085655845, 'colsample_bytree': 0.9508907506795209, 'gamma': 2.9568658844836014e-05, 'lambda': 1.1332623986265841e-06, 'alpha': 9.815274287678795}. Best is trial 26 with value: 2.284621149519712.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:41:43,752] Trial 30 finished with value: 2.3517577428977092 and parameters: {'max_depth': 7, 'learning_rate': 0.17501061541216129, 'n_estimators': 929, 'subsample': 0.9233618723876386, 'colsample_bytree': 0.8328182640955073, 'gamma': 2.3490543657060223e-06, 'lambda': 5.157308484675485e-05, 'alpha': 0.12737710444002306}. Best is trial 26 with value: 2.284621149519712.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:43:07,878] Trial 31 finished with value: 2.280593651297142 and parameters: {'max_depth': 9, 'learning_rate': 0.12858311197181305, 'n_estimators': 1000, 'subsample': 0.9703867177265195, 'colsample_bytree': 0.8912225538392051, 'gamma': 0.0006888252605090775, 'lambda': 0.005001346208039952, 'alpha': 2.2712544881405696}. Best is trial 31 with value: 2.280593651297142.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:44:28,557] Trial 32 finished with value: 2.2889620859080857 and parameters: {'max_depth': 9, 'learning_rate': 0.12709058680022536, 'n_estimators': 932, 'subsample': 0.9648031320079704, 'colsample_bytree': 0.8669577612614066, 'gamma': 0.0001532596710210252, 'lambda': 0.07233669540139788, 'alpha': 2.6072274604605687}. Best is trial 31 with value: 2.280593651297142.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:46:00,673] Trial 33 finished with value: 2.271858363082769 and parameters: {'max_depth': 10, 'learning_rate': 0.12424146810388925, 'n_estimators': 910, 'subsample': 0.9667809978810703, 'colsample_bytree': 0.8805159914564822, 'gamma': 0.00023092324568992724, 'lambda': 0.7702728018211011, 'alpha': 1.2006443757812042}. Best is trial 33 with value: 2.271858363082769.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:47:37,350] Trial 34 finished with value: 2.278611059670791 and parameters: {'max_depth': 10, 'learning_rate': 0.12064091939698232, 'n_estimators': 934, 'subsample': 0.7599818047125483, 'colsample_bytree': 0.8808847866979118, 'gamma': 0.0024738154928590148, 'lambda': 0.9774668422437418, 'alpha': 1.2533348727424678}. Best is trial 33 with value: 2.271858363082769.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:49:20,957] Trial 35 finished with value: 2.3034554503530416 and parameters: {'max_depth': 10, 'learning_rate': 0.06896054267087226, 'n_estimators': 938, 'subsample': 0.7903678250337052, 'colsample_bytree': 0.952620238106675, 'gamma': 0.037419483548012056, 'lambda': 1.7901244722246092, 'alpha': 1.1224424429141147}. Best is trial 33 with value: 2.271858363082769.\n[I 2025-01-30 20:51:03,023] Trial 36 finished with value: 2.28198296410745 and parameters: {'max_depth': 10, 'learning_rate': 0.09338461079922078, 'n_estimators': 999, 'subsample': 0.7510229322924474, 'colsample_bytree': 0.9215553885418484, 'gamma': 0.0023506472920615876, 'lambda': 1.1027950104342672, 'alpha': 0.029792477409486866}. Best is trial 33 with value: 2.271858363082769.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:52:46,473] Trial 37 finished with value: 2.3250409953905975 and parameters: {'max_depth': 10, 'learning_rate': 0.046716580111933456, 'n_estimators': 1000, 'subsample': 0.7647226093230117, 'colsample_bytree': 0.8873758924877919, 'gamma': 0.38507620006275906, 'lambda': 0.8446808098560308, 'alpha': 0.036281566437927654}. Best is trial 33 with value: 2.271858363082769.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:54:10,899] Trial 38 finished with value: 2.304080640256237 and parameters: {'max_depth': 10, 'learning_rate': 0.1058168978076421, 'n_estimators': 805, 'subsample': 0.7340421872910852, 'colsample_bytree': 0.9108022929788144, 'gamma': 0.003059400503317953, 'lambda': 3.4328354899052034, 'alpha': 0.001001546472782512}. Best is trial 33 with value: 2.271858363082769.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:55:43,032] Trial 39 finished with value: 2.3191110585247388 and parameters: {'max_depth': 10, 'learning_rate': 0.0600839300008524, 'n_estimators': 839, 'subsample': 0.7602069041222029, 'colsample_bytree': 0.9615721888480155, 'gamma': 0.026235228883299315, 'lambda': 0.3390898020542384, 'alpha': 0.9147620186670156}. Best is trial 33 with value: 2.271858363082769.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:57:18,975] Trial 40 finished with value: 2.4979163628200327 and parameters: {'max_depth': 9, 'learning_rate': 0.013035289740409529, 'n_estimators': 758, 'subsample': 0.8181868091313913, 'colsample_bytree': 0.9198252974382487, 'gamma': 0.005229498668545593, 'lambda': 0.102047766169371, 'alpha': 0.04405499974591316}. Best is trial 33 with value: 2.271858363082769.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 20:58:54,582] Trial 41 finished with value: 2.3020171902037743 and parameters: {'max_depth': 10, 'learning_rate': 0.09159941684474764, 'n_estimators': 919, 'subsample': 0.7135958536457295, 'colsample_bytree': 0.8881614121672251, 'gamma': 0.0009561503189145928, 'lambda': 3.0355140008521286, 'alpha': 0.27471758552601316}. Best is trial 33 with value: 2.271858363082769.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 21:00:31,180] Trial 42 finished with value: 2.2975139131407474 and parameters: {'max_depth': 10, 'learning_rate': 0.12077644755657005, 'n_estimators': 957, 'subsample': 0.7383147725318253, 'colsample_bytree': 0.9252905574037233, 'gamma': 0.0002644517498007042, 'lambda': 3.3340745147584605e-07, 'alpha': 0.11076909989160341}. Best is trial 33 with value: 2.271858363082769.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 21:02:08,186] Trial 43 finished with value: 2.297212177581685 and parameters: {'max_depth': 10, 'learning_rate': 0.09081683568420165, 'n_estimators': 912, 'subsample': 0.6708246468480781, 'colsample_bytree': 0.9994102820778672, 'gamma': 0.11407404626614359, 'lambda': 0.5452820084916306, 'alpha': 1.5125981124502341}. Best is trial 33 with value: 2.271858363082769.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 21:03:28,973] Trial 44 finished with value: 2.3163493825646575 and parameters: {'max_depth': 9, 'learning_rate': 0.14621684622434655, 'n_estimators': 946, 'subsample': 0.7843968812814254, 'colsample_bytree': 0.9652991283265715, 'gamma': 0.009932594085697239, 'lambda': 0.19332990640375824, 'alpha': 0.00297444607678074}. Best is trial 33 with value: 2.271858363082769.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 21:03:55,510] Trial 45 finished with value: 2.562566321373166 and parameters: {'max_depth': 4, 'learning_rate': 0.04847284785857608, 'n_estimators': 782, 'subsample': 0.7086340007483892, 'colsample_bytree': 0.88577513177071, 'gamma': 0.003997287391808462, 'lambda': 0.0002986614189735406, 'alpha': 0.019277099227944936}. Best is trial 33 with value: 2.271858363082769.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 21:05:41,938] Trial 46 finished with value: 2.286414725801238 and parameters: {'max_depth': 10, 'learning_rate': 0.07128997730428792, 'n_estimators': 1000, 'subsample': 0.7731308902805526, 'colsample_bytree': 0.9806728532187524, 'gamma': 5.639722543810403e-05, 'lambda': 0.02825663505527486, 'alpha': 0.1746873184382834}. Best is trial 33 with value: 2.271858363082769.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 21:07:05,432] Trial 47 finished with value: 2.2737972534976 and parameters: {'max_depth': 10, 'learning_rate': 0.11841844620068986, 'n_estimators': 893, 'subsample': 0.9782324945899898, 'colsample_bytree': 0.6862301582229194, 'gamma': 0.0015733203226392085, 'lambda': 2.203695414302962e-06, 'alpha': 0.00028992411655613193}. Best is trial 33 with value: 2.271858363082769.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 21:08:14,197] Trial 48 finished with value: 2.3026414999091274 and parameters: {'max_depth': 9, 'learning_rate': 0.11242814788262087, 'n_estimators': 877, 'subsample': 0.8446379075178361, 'colsample_bytree': 0.6421482698404716, 'gamma': 0.0007843858155414459, 'lambda': 2.87689732070214e-08, 'alpha': 0.00010454050537625587}. Best is trial 33 with value: 2.271858363082769.\n<ipython-input-10-92eacff5d77e>:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n<ipython-input-10-92eacff5d77e>:53: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:54: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n<ipython-input-10-92eacff5d77e>:55: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n<ipython-input-10-92eacff5d77e>:56: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'lambda': trial.suggest_loguniform('lambda', 1e-8, 10.0),\n<ipython-input-10-92eacff5d77e>:57: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n  'alpha': trial.suggest_loguniform('alpha', 1e-8, 10.0),\n[I 2025-01-30 21:08:30,351] Trial 49 finished with value: 2.4930268170426 and parameters: {'max_depth': 5, 'learning_rate': 0.16505736409041855, 'n_estimators': 449, 'subsample': 0.8115438020590952, 'colsample_bytree': 0.7027244399767048, 'gamma': 0.013608861327186302, 'lambda': 1.8999189370198348, 'alpha': 1.7081418850725826e-05}. Best is trial 33 with value: 2.271858363082769.\n","output_type":"stream"},{"name":"stdout","text":"Best Parameters: {'max_depth': 10, 'learning_rate': 0.12424146810388925, 'n_estimators': 910, 'subsample': 0.9667809978810703, 'colsample_bytree': 0.8805159914564822, 'gamma': 0.00023092324568992724, 'lambda': 0.7702728018211011, 'alpha': 1.2006443757812042}\nFinal RMSE: 2.271858363082769\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\n# Load Data\ndata = pd.read_csv('/kaggle/input/datasss/Sampling_data.csv')\n\n# Convert to DataFrame\ndf = pd.DataFrame(data)\n\n# Convert categorical columns to numeric (if not already)\ndf['Drug Name'] = df['Drug Name'].astype('category').cat.codes\ndf['condition'] = df['condition'].astype('category').cat.codes\n\n# Step 1: Handle the 'review' column using TF-IDF vectorizer\ntfidf = TfidfVectorizer(stop_words='english', max_features=200)\nreview_features = tfidf.fit_transform(df['review']).toarray()\n\n# Convert the review features to a DataFrame (Ensure it's 1D)\nreview_df = pd.DataFrame(review_features, columns=tfidf.get_feature_names_out())\n\n# Combine the review features with other features\ndf = pd.concat([df, review_df], axis=1)\n\n# Drop the original 'review' column\ndf.drop(columns=['review'], inplace=True)\n\n# Features and target\nfeatures = ['Drug Name', 'condition', 'usefulCount'] + list(review_df.columns)\ntarget = 'rating'\n\n# Step 2: Split data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=42)\n\n# Feature Scaling\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Step 3: Build a simpler Neural Network Model using Keras\nmodel = tf.keras.Sequential()\n\n# Input layer (features)\nmodel.add(tf.keras.layers.InputLayer(input_shape=(X_train_scaled.shape[1],)))\n\n# Hidden layers (simplified architecture with fewer units)\nmodel.add(tf.keras.layers.Dense(64, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.2))  # Dropout for regularization\nmodel.add(tf.keras.layers.Dense(32, activation='relu'))\n\n# Output layer (for regression)\nmodel.add(tf.keras.layers.Dense(1))\n\n# Compile the model with Adam optimizer and MSE loss\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# Step 4: Implement Early Stopping and Reduce Epochs\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n# Train the model with a limited number of epochs and early stopping\nhistory = model.fit(X_train_scaled, y_train, epochs=30, batch_size=64, validation_data=(X_test_scaled, y_test),\n                    verbose=1, callbacks=[early_stopping])\n\n# Step 5: Evaluate the model\ny_pred = model.predict(X_test_scaled)\n\n# Calculate RMSE manually\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nprint(f\"Final RMSE: {rmse}\")\n\n# Calculate MAE and R2\nmae = mean_absolute_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"R-squared (R2): {r2}\")\n\n# Step 6: Track and display the train and validation losses\ntrain_loss = history.history['loss'][-1]  # Final loss on training set\nval_loss = history.history['val_loss'][-1]  # Final loss on validation set\n\nprint(f\"Training Loss (MSE): {train_loss}\")\nprint(f\"Validation Loss (MSE): {val_loss}\")\n\n# Step 7: Compare Actual vs Predicted Ratings\nresults = pd.DataFrame({'Actual Rating': y_test, 'Predicted Rating': np.round(y_pred)})\nprint(results.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T11:22:07.876196Z","iopub.execute_input":"2025-02-01T11:22:07.876695Z","iopub.status.idle":"2025-02-01T11:23:01.911058Z","shell.execute_reply.started":"2025-02-01T11:22:07.876654Z","shell.execute_reply":"2025-02-01T11:23:01.909845Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 16.0625 - val_loss: 7.6695\nEpoch 2/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7.7992 - val_loss: 7.1986\nEpoch 3/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7.2673 - val_loss: 7.0333\nEpoch 4/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7.0061 - val_loss: 6.9888\nEpoch 5/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6.8637 - val_loss: 6.8582\nEpoch 6/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6.7668 - val_loss: 6.8391\nEpoch 7/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6.7308 - val_loss: 6.8105\nEpoch 8/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6.6440 - val_loss: 6.7678\nEpoch 9/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.5414 - val_loss: 6.7413\nEpoch 10/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.3954 - val_loss: 6.7340\nEpoch 11/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6.2735 - val_loss: 6.7227\nEpoch 12/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6.1951 - val_loss: 6.7004\nEpoch 13/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6.1551 - val_loss: 6.6995\nEpoch 14/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6.0192 - val_loss: 6.6653\nEpoch 15/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5.9391 - val_loss: 6.7782\nEpoch 16/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5.9351 - val_loss: 6.6351\nEpoch 17/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5.9077 - val_loss: 6.7275\nEpoch 18/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5.8193 - val_loss: 6.6356\nEpoch 19/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5.7757 - val_loss: 6.6636\nEpoch 20/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5.7672 - val_loss: 6.6414\nEpoch 21/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5.6867 - val_loss: 6.6209\nEpoch 22/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5.6067 - val_loss: 6.5964\nEpoch 23/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5.5924 - val_loss: 6.5894\nEpoch 24/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5.5508 - val_loss: 6.5640\nEpoch 25/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5.4063 - val_loss: 6.6165\nEpoch 26/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5.4351 - val_loss: 6.5774\nEpoch 27/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5.4432 - val_loss: 6.6455\nEpoch 28/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5.4004 - val_loss: 6.7269\nEpoch 29/30\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5.3599 - val_loss: 6.6489\n\u001b[1m493/493\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\nFinal RMSE: 2.562033895123277\nMean Absolute Error (MAE): 1.9831179975139948\nR-squared (R2): 0.3561242079997461\nTraining Loss (MSE): 5.460657596588135\nValidation Loss (MSE): 6.648933410644531\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-73256fbc5d44>\u001b[0m in \u001b[0;36m<cell line: 90>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;31m# Step 7: Compare Actual vs Predicted Ratings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Actual Rating'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Predicted Rating'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0mraw_lengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Per-column arrays must each be 1-dimensional\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraw_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Per-column arrays must each be 1-dimensional"],"ename":"ValueError","evalue":"Per-column arrays must each be 1-dimensional","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import mean_squared_error\n\n# Load Data\ndata = pd.read_csv('/kaggle/input/main-dataset/Sampling_data.csv')\n\n# Convert to DataFrame\ndf = pd.DataFrame(data)\n\n# Convert categorical columns to numeric (if not already)\ndf['Drug Name'] = df['Drug Name'].astype('category').cat.codes\ndf['condition'] = df['condition'].astype('category').cat.codes\n\n# Step 1: Handle the 'review' column using TF-IDF vectorizer\ntfidf = TfidfVectorizer(stop_words='english', max_features=200)\nreview_features = tfidf.fit_transform(df['review']).toarray()\n\n# Convert the review features to a DataFrame\nreview_df = pd.DataFrame(review_features, columns=tfidf.get_feature_names_out())\n\n# Combine the review features with other features\ndf = pd.concat([df, review_df], axis=1)\n\n# Drop the original 'review' column\ndf.drop(columns=['review'], inplace=True)\n\n# Features and target\nfeatures = ['Drug Name', 'condition', 'usefulCount'] + list(review_df.columns)\ntarget = 'rating'\n\n# Step 2: Split data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=42)\n\n# Feature Scaling\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Step 3: Build Neural Network Model using Keras\nmodel = tf.keras.Sequential()\n\n# Input layer (features)\nmodel.add(tf.keras.layers.InputLayer(input_shape=(X_train_scaled.shape[1],)))\n\n# Hidden layers (you can tune the number of layers and units)\nmodel.add(tf.keras.layers.Dense(128, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.3))  # Dropout for regularization\nmodel.add(tf.keras.layers.Dense(64, activation='relu'))\nmodel.add(tf.keras.layers.Dropout(0.3))  # Dropout for regularization\nmodel.add(tf.keras.layers.Dense(32, activation='relu'))\n\n# Output layer (for regression)\nmodel.add(tf.keras.layers.Dense(1))\n\n# Compile the model with Adam optimizer and MSE loss\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n\n# Step 4: Train the model\nhistory = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test), verbose=1)\n\n# Step 5: Evaluate the model\ny_pred = model.predict(X_test_scaled)\n\n# Calculate RMSE manually\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nprint(f\"Final RMSE: {rmse}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T21:12:57.217295Z","iopub.execute_input":"2025-01-30T21:12:57.217676Z","iopub.status.idle":"2025-01-30T21:15:46.646322Z","shell.execute_reply.started":"2025-01-30T21:12:57.217647Z","shell.execute_reply":"2025-01-30T21:15:46.645508Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 10.9300 - val_loss: 10.2951\nEpoch 2/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7.6807 - val_loss: 10.1456\nEpoch 3/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 7.1442 - val_loss: 9.7280\nEpoch 4/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6.9226 - val_loss: 8.3232\nEpoch 5/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6.7489 - val_loss: 8.6828\nEpoch 6/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6.6695 - val_loss: 8.5963\nEpoch 7/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6.4573 - val_loss: 8.9320\nEpoch 8/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6.4799 - val_loss: 8.9073\nEpoch 9/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6.3200 - val_loss: 9.0454\nEpoch 10/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6.1992 - val_loss: 8.7483\nEpoch 11/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6.0763 - val_loss: 8.7706\nEpoch 12/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6.1256 - val_loss: 8.9738\nEpoch 13/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 6.0495 - val_loss: 8.2950\nEpoch 14/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.9481 - val_loss: 8.8648\nEpoch 15/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.8392 - val_loss: 8.5388\nEpoch 16/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.7227 - val_loss: 8.5164\nEpoch 17/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.7141 - val_loss: 8.6843\nEpoch 18/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.7221 - val_loss: 8.3248\nEpoch 19/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.6143 - val_loss: 8.4054\nEpoch 20/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.5677 - val_loss: 8.0655\nEpoch 21/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.5828 - val_loss: 7.9533\nEpoch 22/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.4285 - val_loss: 7.7989\nEpoch 23/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.4483 - val_loss: 8.2518\nEpoch 24/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.3277 - val_loss: 8.7880\nEpoch 25/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.3312 - val_loss: 8.2114\nEpoch 26/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.2683 - val_loss: 8.0415\nEpoch 27/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.2530 - val_loss: 7.7978\nEpoch 28/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.2066 - val_loss: 7.8168\nEpoch 29/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.1858 - val_loss: 7.5711\nEpoch 30/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.1727 - val_loss: 8.0152\nEpoch 31/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.1703 - val_loss: 7.8996\nEpoch 32/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.0863 - val_loss: 7.7572\nEpoch 33/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.0041 - val_loss: 7.6970\nEpoch 34/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.0923 - val_loss: 7.4859\nEpoch 35/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.9839 - val_loss: 7.2587\nEpoch 36/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 5.0047 - val_loss: 7.2306\nEpoch 37/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.8658 - val_loss: 6.9950\nEpoch 38/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.9150 - val_loss: 7.1594\nEpoch 39/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.8954 - val_loss: 7.3028\nEpoch 40/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.8106 - val_loss: 6.9972\nEpoch 41/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.7871 - val_loss: 6.8715\nEpoch 42/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.8248 - val_loss: 6.7101\nEpoch 43/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.7747 - val_loss: 6.6910\nEpoch 44/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.6990 - val_loss: 6.8952\nEpoch 45/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.6918 - val_loss: 6.7508\nEpoch 46/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.7205 - val_loss: 6.7497\nEpoch 47/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.6929 - val_loss: 6.9668\nEpoch 48/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.6378 - val_loss: 6.7727\nEpoch 49/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.6134 - val_loss: 6.8222\nEpoch 50/50\n\u001b[1m1971/1971\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 4.6085 - val_loss: 6.8832\n\u001b[1m493/493\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\nFinal RMSE: 2.6235784820239525\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, BatchNormalization\nfrom keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\n\n# Load and preprocess your data\ndf = pd.read_csv('/kaggle/input/main-dataset/Sampling_data.csv')\ndf['Drug Name'] = df['Drug Name'].astype('category').cat.codes\ndf['condition'] = df['condition'].astype('category').cat.codes\n\n# TF-IDF for the 'review' column\ntfidf = TfidfVectorizer(stop_words='english', max_features=200)\nreview_features = tfidf.fit_transform(df['review']).toarray()\nreview_df = pd.DataFrame(review_features, columns=tfidf.get_feature_names_out())\ndf = pd.concat([df, review_df], axis=1)\ndf.drop(columns=['review'], inplace=True)\n\n# Features and target\nfeatures = ['Drug Name', 'condition', 'usefulCount'] + list(review_df.columns)\ntarget = 'rating'\n\n# Split the data\nX = df[features].values\ny = df[target].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Feature Scaling\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Define and compile the neural network with modifications\nmodel = Sequential()\nmodel.add(Dense(512, input_dim=X_train_scaled.shape[1], activation='relu'))\nmodel.add(BatchNormalization())  # Added batch normalization for faster convergence\nmodel.add(Dropout(0.3))  # Increased dropout to reduce overfitting\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(64, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(1))  # Output layer for regression (rating prediction)\n\nmodel.compile(optimizer='adam', loss='mse')\n\n# EarlyStopping callback to monitor validation loss\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\n# Train the model\nhistory = model.fit(X_train_scaled, y_train, epochs=100, batch_size=64, \n                    validation_data=(X_test_scaled, y_test), verbose=1, \n                    callbacks=[early_stopping])\n\n# Evaluate the model\nloss = model.evaluate(X_test_scaled, y_test)\nprint(f\"Test Loss: {loss}\")\n\n# Predict and calculate RMSE\ny_pred = model.predict(X_test_scaled)\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nprint(f\"RMSE: {rmse}\")\n\n# Plot the training and validation loss curves\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T21:23:43.056762Z","iopub.execute_input":"2025-01-30T21:23:43.057228Z","iopub.status.idle":"2025-01-30T21:25:25.257844Z","shell.execute_reply.started":"2025-01-30T21:23:43.057194Z","shell.execute_reply":"2025-01-30T21:25:25.256966Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - loss: 32.4101 - val_loss: 7.1472\nEpoch 2/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 8.4692 - val_loss: 6.8500\nEpoch 3/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.6530 - val_loss: 6.7136\nEpoch 4/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.0860 - val_loss: 6.6350\nEpoch 5/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.7428 - val_loss: 6.5521\nEpoch 6/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.4391 - val_loss: 6.4586\nEpoch 7/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.1185 - val_loss: 6.3854\nEpoch 8/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.8690 - val_loss: 6.2687\nEpoch 9/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.6614 - val_loss: 6.1975\nEpoch 10/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.3806 - val_loss: 6.1522\nEpoch 11/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.1929 - val_loss: 6.2133\nEpoch 12/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.0167 - val_loss: 6.1419\nEpoch 13/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.9477 - val_loss: 6.1741\nEpoch 14/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.7549 - val_loss: 6.0567\nEpoch 15/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.5288 - val_loss: 6.0935\nEpoch 16/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.5118 - val_loss: 6.0754\nEpoch 17/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.4065 - val_loss: 6.2043\nEpoch 18/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.3127 - val_loss: 6.1324\nEpoch 19/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.2010 - val_loss: 6.0705\nEpoch 20/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.0612 - val_loss: 6.0963\nEpoch 21/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.0636 - val_loss: 6.0028\nEpoch 22/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.8938 - val_loss: 6.2038\nEpoch 23/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.9149 - val_loss: 6.0956\nEpoch 24/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.7808 - val_loss: 6.0788\nEpoch 25/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.7747 - val_loss: 5.9670\nEpoch 26/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.6797 - val_loss: 6.0975\nEpoch 27/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.6499 - val_loss: 5.9773\nEpoch 28/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.6142 - val_loss: 6.1495\nEpoch 29/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.5196 - val_loss: 6.1499\nEpoch 30/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.5028 - val_loss: 6.0150\nEpoch 31/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.4454 - val_loss: 6.0769\nEpoch 32/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.3767 - val_loss: 6.0782\nEpoch 33/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.4118 - val_loss: 6.1262\nEpoch 34/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.3513 - val_loss: 6.0509\nEpoch 35/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.3003 - val_loss: 6.0702\n\u001b[1m493/493\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5.8394\nTest Loss: 5.966973781585693\n\u001b[1m493/493\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\nRMSE: 2.4427391492444617\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAjMAAAGwCAYAAABcnuQpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABULUlEQVR4nO3deXwTdf4/8NckadIz6X1BSwuUG4pyCSqCsEJF5HLxYKWe/EAOEXGRVRR0XbwXry+ouwuy4qLuCrIqIrBcIjeWQ0qhUNoCPaBXmh5Jm8zvj2nSBtrSI8kk7ev5eMwjycxk8u50IK9+Pp+ZEURRFEFERETkoRRyF0BERETUGgwzRERE5NEYZoiIiMijMcwQERGRR2OYISIiIo/GMENEREQejWGGiIiIPJpK7gKczWKx4PLlywgICIAgCHKXQ0RERE0giiJKS0sRHR0NhaLxtpc2H2YuX76MmJgYucsgIiKiFsjOzkbHjh0bXafNh5mAgAAA0s7QarUyV0NERERNodfrERMTY/seb0ybDzPWriWtVsswQ0RE5GGaMkSEA4CJiIjIozHMEBERkUdjmCEiIiKP1ubHzBARUetYLBaYTCa5y6A2xsvLC0ql0iHbYpghIqIGmUwmZGRkwGKxyF0KtUGBgYGIjIxs9XXgGGaIiKheoigiJycHSqUSMTExN7xwGVFTiaKI8vJy5OfnAwCioqJatT2GGSIiqld1dTXKy8sRHR0NX19fucuhNsbHxwcAkJ+fj/Dw8FZ1OTFmExFRvcxmMwBArVbLXAm1VdaQXFVV1artMMwQEVGjeF87chZHHVsMM0REROTRGGaIiIjIozHMEBER3UBcXBxWrFjR5PV37twJQRBQXFzstJqoFsNMC5WbqnGxqBz5pZVyl0JERDUEQWh0Wrp0aYu2e+jQIcyYMaPJ6w8bNgw5OTnQ6XQt+rymYmiS8NTsFvp413m8t/0spg2JxWuT+spdDhERAcjJybE9//LLL/HSSy8hLS3NNs/f39/2XBRFmM1mqFQ3/ioMCwtrVh1qtRqRkZHNeg+1HFtmWijAWzr4SyurZa6EiMg1RFFEualalkkUxSbVGBkZaZt0Oh0EQbC9Pn36NAICArB582YMGDAAGo0GP//8M86dO4cJEyYgIiIC/v7+GDRoELZt22a33Wu7mQRBwN/+9jdMmjQJvr6+SEhIwKZNm2zLr20xWbNmDQIDA7Flyxb07NkT/v7+GDt2rF34qq6uxrx58xAYGIiQkBAsWrQIycnJmDhxYot/Z0VFRZg+fTqCgoLg6+uLpKQknD171rY8MzMT48ePR1BQEPz8/NC7d2/88MMPtvdOmzYNYWFh8PHxQUJCAlavXt3iWpyJLTMtpPX2AgCUVrbu3HgiIk9RUWVGr5e2yPLZp14ZA1+1Y76ynn/+ebz99tvo3LkzgoKCkJ2djbvvvhuvvfYaNBoN1q5di/HjxyMtLQ2xsbENbmfZsmV488038dZbb+GDDz7AtGnTkJmZieDg4HrXLy8vx9tvv41//vOfUCgU+MMf/oCFCxdi3bp1AIA33ngD69atw+rVq9GzZ0+899572LhxI0aOHNnin/WRRx7B2bNnsWnTJmi1WixatAh33303Tp06BS8vL8yePRsmkwm7d++Gn58fTp06ZWu9WrJkCU6dOoXNmzcjNDQU6enpqKioaHEtzsQw00JsmSEi8kyvvPIKfve739leBwcHIzEx0fb61VdfxYYNG7Bp0ybMmTOnwe088sgjePDBBwEAf/nLX/D+++/j4MGDGDt2bL3rV1VVYdWqVejSpQsAYM6cOXjllVdsyz/44AMsXrwYkyZNAgB8+OGHtlaSlrCGmL1792LYsGEAgHXr1iEmJgYbN27E73//e2RlZWHKlCno21caLtG5c2fb+7OysnDTTTdh4MCBAKTWKXfFMNNCAbaWGYYZImoffLyUOPXKGNk+21GsX85WBoMBS5cuxffff4+cnBxUV1ejoqICWVlZjW6nX79+tud+fn7QarW2ew3Vx9fX1xZkAOl+RNb1S0pKkJeXh8GDB9uWK5VKDBgwoMU3+UxNTYVKpcKQIUNs80JCQtC9e3ekpqYCAObNm4dZs2bhp59+wujRozFlyhTbzzVr1ixMmTIFR48exV133YWJEyfaQpG7kXXMzO7duzF+/HhER0dDEARs3LjRbrnBYMCcOXPQsWNH+Pj4oFevXli1apU8xV6jtmWG3UxE1D4IggBftUqWyZFXIfbz87N7vXDhQmzYsAF/+ctfsGfPHqSkpKBv374wmUyNbsfLy+u6/dNY8Khv/aaOBXKWJ554AufPn8fDDz+MEydOYODAgfjggw8AAElJScjMzMQzzzyDy5cvY9SoUVi4cKGs9TZE1jBTVlaGxMREfPTRR/UuX7BgAX788Ud8/vnnSE1Nxfz58zFnzhy7QVZyYTcTEVHbsHfvXjzyyCOYNGkS+vbti8jISFy4cMGlNeh0OkRERODQoUO2eWazGUePHm3xNnv27Inq6mocOHDANq+goABpaWno1auXbV5MTAxmzpyJb775Bs8++yw+/fRT27KwsDAkJyfj888/x4oVK/DJJ5+0uB5nkrWbKSkpCUlJSQ0u/+WXX5CcnIwRI0YAAGbMmIGPP/4YBw8exL333uuiKutn7WYymKphsYhQKHjvEiIiT5SQkIBvvvkG48ePhyAIWLJkSYu7dlpj7ty5WL58Obp27YoePXrggw8+QFFRUZNapU6cOIGAgADba0EQkJiYiAkTJuDJJ5/Exx9/jICAADz//PPo0KEDJkyYAACYP38+kpKS0K1bNxQVFWHHjh3o2bMnAOCll17CgAED0Lt3bxiNRnz33Xe2Ze7GrcfMDBs2DJs2bcJjjz2G6Oho7Ny5E2fOnMFf//rXBt9jNBphNBptr/V6vVNqs7bMiKIUaKxnNxERkWd599138dhjj2HYsGEIDQ3FokWLnPbd0ZhFixYhNzcX06dPh1KpxIwZMzBmzBgolTceLzR8+HC710qlEtXV1Vi9ejWefvpp3HPPPTCZTBg+fDh++OEHW5eX2WzG7NmzcfHiRWi1WowdO9b2HatWq7F48WJcuHABPj4+uP3227F+/XrH/+AOIIhyd9jVEAQBGzZssDuf3mg0YsaMGVi7di1UKhUUCgU+/fRTTJ8+vcHtLF26FMuWLbtufklJCbRarUNr7vbCZpjMFux9/k50CPRx6LaJiORWWVmJjIwMxMfHw9vbW+5y2h2LxYKePXti6tSpePXVV+UuxykaO8b0ej10Ol2Tvr/d+qJ5H3zwAfbv349NmzbhyJEjeOeddzB79uzrLmZU1+LFi1FSUmKbsrOznVYfBwETEZGjZGZm4tNPP8WZM2dw4sQJzJo1CxkZGXjooYfkLs3tuW03U0VFBf70pz9hw4YNGDduHADpNLiUlBS8/fbbGD16dL3v02g00Gg0LqkxwFuFgjITBwETEVGrKRQKrFmzBgsXLoQoiujTpw+2bdvmtuNU3InbhpmqqipUVVVBobBvPFIqlbIMzKpPAK8CTEREDhITE4O9e/fKXYZHkjXMGAwGpKen215nZGQgJSUFwcHBiI2NxR133IHnnnsOPj4+6NSpE3bt2oW1a9fi3XfflbHqWjw9m4iISH6yhpnDhw/b3XNiwYIFAIDk5GSsWbMG69evx+LFizFt2jQUFhaiU6dOeO211zBz5ky5SrZjDTN6hhkiIiLZyBpmRowY0ejVDyMjI932Dp0Au5mIiIjcgVufzeTu2M1EREQkP4aZVrBdBZhhhoiISDYMM62g5XVmiIjapBEjRmD+/Pm213FxcVixYkWj76nvhskt4ajttCcMM63AbiYiIvcyfvx4jB07tt5le/bsgSAIOH78eLO3e+jQIcyYMaO15dlZunQp+vfvf938nJycRu9b6Ahr1qxBYGCgUz/DlRhmWqF2ADDDDBGRO3j88cexdetWXLx48bplq1evxsCBA9GvX79mbzcsLAy+vr6OKPGGIiMjXXbx17aCYaYVak/NZjcTEZE7uOeeexAWFoY1a9bYzTcYDPj666/x+OOPo6CgAA8++CA6dOgAX19f9O3bF//6178a3e613Uxnz57F8OHD4e3tjV69emHr1q3XvWfRokXo1q0bfH190blzZyxZsgRVVdL3xZo1a7Bs2TIcO3YMgiBAEARbzdd2M504cQJ33nknfHx8EBISghkzZsBgMNiWP/LII5g4cSLefvttREVFISQkBLNnz7Z9VktkZWVhwoQJ8Pf3h1arxdSpU5GXl2dbfuzYMYwcORIBAQHQarUYMGAADh8+DEC6LcP48eMRFBQEPz8/9O7dGz/88EOLa2kKt70CsCfw17CbiYjaEVEEqsrl+WwvX0AQbriaSqXC9OnTsWbNGrzwwgsQat7z9ddfw2w248EHH4TBYMCAAQOwaNEiaLVafP/993j44YfRpUsXDB48+IafYbFYMHnyZERERODAgQMoKSmxG19jFRAQgDVr1iA6OhonTpzAk08+iYCAAPzxj3/E/fffj5MnT+LHH3+03W9Qp9Ndt42ysjKMGTMGQ4cOxaFDh5Cfn48nnngCc+bMsQtsO3bsQFRUFHbs2IH09HTcf//96N+/P5588skb/jz1/XzWILNr1y5UV1dj9uzZuP/++7Fz504AwLRp03DTTTdh5cqVUCqVSElJsd2Je/bs2TCZTNi9ezf8/Pxw6tQp+Pv7N7uO5mCYaQVeZ4aI2pWqcuAv0fJ89p8uA2q/Jq362GOP4a233sKuXbswYsQIAFIX05QpU6DT6aDT6bBw4ULb+nPnzsWWLVvw1VdfNSnMbNu2DadPn8aWLVsQHS3tj7/85S/XjXN58cUXbc/j4uKwcOFCrF+/Hn/84x/h4+MDf39/qFQqREZGNvhZX3zxBSorK7F27Vr4+Uk//4cffojx48fjjTfeQEREBAAgKCgIH374IZRKJXr06IFx48Zh+/btLQoz27dvx4kTJ5CRkYGYmBgAwNq1a9G7d28cOnQIgwYNQlZWFp577jn06NEDAJCQkGB7f1ZWFqZMmYK+ffsCADp37tzsGpqL3UytYD2byWCsbvTif0RE5Do9evTAsGHD8I9//AMAkJ6ejj179uDxxx8HAJjNZrz66qvo27cvgoOD4e/vjy1btiArK6tJ209NTUVMTIwtyADA0KFDr1vvyy+/xK233orIyEj4+/vjxRdfbPJn1P2sxMREW5ABgFtvvRUWiwVpaWm2eb1794ZSqbS9joqKQn5+frM+q+5nxsTE2IIMAPTq1QuBgYFITU0FIF2x/4knnsDo0aPx+uuv49y5c7Z1582bhz//+c+49dZb8fLLL7dowHVzsWWmFawtMxYRKDOZbd1ORERtkpev1EIi12c3w+OPP465c+fio48+wurVq9GlSxfccccdAIC33noL7733HlasWIG+ffvCz88P8+fPh8lkcli5+/btw7Rp07Bs2TKMGTMGOp0O69evxzvvvOOwz6jL2sVjJQiCU2/KvHTpUjz00EP4/vvvsXnzZrz88stYv349Jk2ahCeeeAJjxozB999/j59++gnLly/HO++8g7lz5zqtHrbMtIK3lwIqhdQfy64mImrzBEHq6pFjasJ4mbqmTp0KhUKBL774AmvXrsVjjz1mGz+zd+9eTJgwAX/4wx+QmJiIzp0748yZM03eds+ePZGdnY2cnBzbvP3799ut88svv6BTp0544YUXMHDgQCQkJCAzM9NuHbVaDbPZfMPPOnbsGMrKymzz9u7dC4VCge7duze55uaw/nzZ2dm2eadOnUJxcTF69eplm9etWzc888wz+OmnnzB58mS72w/FxMRg5syZ+Oabb/Dss8/i008/dUqtVgwzrSAIAq81Q0Tkhvz9/XH//fdj8eLFyMnJwSOPPGJblpCQgK1bt+KXX35Bamoq/t//+392Z+rcyOjRo9GtWzckJyfj2LFj2LNnD1544QW7dRISEpCVlYX169fj3LlzeP/997Fhwwa7deLi4pCRkYGUlBRcvXoVRqPxus+aNm0avL29kZycjJMnT2LHjh2YO3cuHn74Ydt4mZYym81ISUmxm1JTUzF69Gj07dsX06ZNw9GjR3Hw4EFMnz4dd9xxBwYOHIiKigrMmTMHO3fuRGZmJvbu3YtDhw6hZ8+eAID58+djy5YtyMjIwNGjR7Fjxw7bMmdhmGklDgImInJPjz/+OIqKijBmzBi78S0vvvgibr75ZowZMwYjRoxAZGQkJk6c2OTtKhQKbNiwARUVFRg8eDCeeOIJvPbaa3br3HvvvXjmmWcwZ84c9O/fH7/88guWLFlit86UKVMwduxYjBw5EmFhYfWeHu7r64stW7agsLAQgwYNwn333YdRo0bhww8/bN7OqIfBYMBNN91kN40fPx6CIODbb79FUFAQhg8fjtGjR6Nz58748ssvAQBKpRIFBQWYPn06unXrhqlTpyIpKQnLli0DIIWk2bNno2fPnhg7diy6deuG//u//2t1vY0RxDY+clWv10On06GkpARardbh2x/3/h78dlmP1Y8Owsju4Q7fPhGRXCorK5GRkYH4+Hh4e3vLXQ61QY0dY835/mbLTCuxm4mIiEheDDOtxG4mIiIieTHMtBJbZoiIiOTFMNNKWrbMEBERyYphppXYMkNEbV0bP0+EZOSoY4thppUYZoiorbJeHt+RV8Ylqqu8XLpx6bVXMG4uXn+/lTgAmIjaKpVKBV9fX1y5cgVeXl5QKPj3LzmGKIooLy9Hfn4+AgMD7e4r1RIMM61kbZnRs2WGiNoYQRAQFRWFjIyM6y7FT+QIgYGBjd41vKkYZlqptmWGYYaI2h61Wo2EhAR2NZHDeXl5tbpFxophppVqx8ywm4mI2iaFQsErAJNbYwdoK2k5AJiIiEhWDDOtZO1mMhirefoiERGRDBhmWsnazWS2iKioMstcDRERUfvDMNNKPl5KKBUCAHY1ERERyYFhppUEQeAgYCIiIhkxzDgArzVDREQkH4YZBwjQ8FozREREcmGYcQB/djMRERHJhmHGAXitGSIiIvkwzDgAbzZJREQkH1nDzO7duzF+/HhER0dDEARs3LjxunVSU1Nx7733QqfTwc/PD4MGDUJWVpbri21EAFtmiIiIZCNrmCkrK0NiYiI++uijepefO3cOt912G3r06IGdO3fi+PHjWLJkidvdI4RhhoiISD6y3mgyKSkJSUlJDS5/4YUXcPfdd+PNN9+0zevSpYsrSmsWazeTnt1MRERELue2Y2YsFgu+//57dOvWDWPGjEF4eDiGDBlSb1dUXUajEXq93m5yNrbMEBERycdtw0x+fj4MBgNef/11jB07Fj/99BMmTZqEyZMnY9euXQ2+b/ny5dDpdLYpJibG6bVyADAREZF83DbMWCwWAMCECRPwzDPPoH///nj++edxzz33YNWqVQ2+b/HixSgpKbFN2dnZTq+VLTNERETykXXMTGNCQ0OhUqnQq1cvu/k9e/bEzz//3OD7NBoNNBqNs8uzw+vMEBERycdtW2bUajUGDRqEtLQ0u/lnzpxBp06dZKqqfuxmIiIiko+sLTMGgwHp6em21xkZGUhJSUFwcDBiY2Px3HPP4f7778fw4cMxcuRI/Pjjj/jvf/+LnTt3yld0Pep2M4miCEEQZK6IiIio/ZA1zBw+fBgjR460vV6wYAEAIDk5GWvWrMGkSZOwatUqLF++HPPmzUP37t3xn//8B7fddptcJdfL2jJTbRFRWWWBj1opc0VERETth6xhZsSIERBFsdF1HnvsMTz22GMuqqhl/NRKKATAIkpdTQwzREREruO2Y2Y8iSAI8NdIuVDPQcBEREQuxTDjIBwETEREJA+GGQfhtWaIiIjkwTDjIFpbywzDDBERkSsxzDhIbcsMu5mIiIhciWHGQdjNREREJA+GGQexDQA2MswQERG5EsOMg7CbiYiISB4MMw4SwAHAREREsmCYcRC2zBAREcmDYcZBOACYiIhIHgwzDsIwQ0REJA+GGQfh7QyIiIjkwTDjIGyZISIikgfDjIPwbCYiIiJ5MMw4iLVlxmS2oLLKLHM1RERE7QfDjIP4q1UQBOk5W2eIiIhch2HGQRQKAf5qXmuGiIjI1RhmHIiDgImIiFyPYcaBOAiYiIjI9RhmHIi3NCAiInI9hhkHYjcTERGR6zHMOJC1m0nPlhkiIiKXYZhxILbMEBERuR7DjANxADAREZHrMcw4EAcAExERuR7DjANp2c1ERETkcgwzDmTrZjKyZYaIiMhVGGYciAOAiYiIXI9hxoE4AJiIiMj1GGYciAOAiYiIXI9hxoGsYUbPlhkiIiKXYZhxIGs3k6naAmO1WeZqiIiI2geGGQfy16hszw1snSEiInIJWcPM7t27MX78eERHR0MQBGzcuLHBdWfOnAlBELBixQqX1ddcSoVgCzQcBExEROQasoaZsrIyJCYm4qOPPmp0vQ0bNmD//v2Ijo52UWUtx9OziYiIXEt141WcJykpCUlJSY2uc+nSJcydOxdbtmzBuHHjbrhNo9EIo9Foe63X61tdZ3PUtszwjCYiIiJXcOsxMxaLBQ8//DCee+459O7du0nvWb58OXQ6nW2KiYlxcpX2eEYTERGRa7l1mHnjjTegUqkwb968Jr9n8eLFKCkpsU3Z2dlOrPB6tRfOY8sMERGRK8jazdSYI0eO4L333sPRo0chCEKT36fRaKDRaJxYWeM4ZoaIiMi13LZlZs+ePcjPz0dsbCxUKhVUKhUyMzPx7LPPIi4uTu7yGsRbGhAREbmW27bMPPzwwxg9erTdvDFjxuDhhx/Go48+KlNVN6blLQ2IiIhcStYwYzAYkJ6ebnudkZGBlJQUBAcHIzY2FiEhIXbre3l5ITIyEt27d3d1qU3GbiYiIiLXkjXMHD58GCNHjrS9XrBgAQAgOTkZa9askamq1rF1MxnZMkNEROQKsoaZESNGQBTFJq9/4cIF5xXjIGyZISIici23HQDsqawtM7zODBERkWswzDhYAAcAExERuRTDjIOxm4mIiMi1GGYcTMsrABMREbkUw4yDWVtmKqssqDJbZK6GiIio7WOYcTDrXbMBdjURERG5AsOMg6mUCviqlQDY1UREROQKDDNOwEHARERErsMw4wS115phywwREZGzMcw4AVtmiIiIXIdhxgls92dimCEiInI6hhkn4FWAiYiIXIdhxgm0NWHGwJYZIiIip2OYcQJbN5ORYYaIiMjZGGacIEDDbiYiIiJXYZhxAuuYGT27mYiIiJyOYcYJ/Hk2ExERkcswzDgBz2YiIiJyHYYZJ+BF84iIiFyHYcYJtLZuJrbMEBERORvDjBOwZYaIiMh1GGacwHqdmXKTGdVmi8zVEBERtW0MM05gbZkBAAMvnEdERORUDDNO4KVUwNtL2rXsaiIiInIuhhknsXY16TkImIiIyKkYZpyEg4CJiIhcg2HGSQJ4FWAiIiKXYJhxEi2vAkxEROQSDDNOwm4mIiIi12CYcZIADa8CTERE5AoMM07ClhkiIiLXYJhxktpTsxlmiIiInIlhxkkCOACYiIjIJRhmnITdTERERK4ha5jZvXs3xo8fj+joaAiCgI0bN9qWVVVVYdGiRejbty/8/PwQHR2N6dOn4/Lly/IV3Ay115lhywwREZEzyRpmysrKkJiYiI8++ui6ZeXl5Th69CiWLFmCo0eP4ptvvkFaWhruvfdeGSptPi1bZoiIiFxCdeNVnCcpKQlJSUn1LtPpdNi6davdvA8//BCDBw9GVlYWYmNj632f0WiE0Wi0vdbr9Y4ruBl4BWAiIiLX8KgxMyUlJRAEAYGBgQ2us3z5cuh0OtsUExPjugLrsI6ZMRgZZoiIiJzJY8JMZWUlFi1ahAcffBBarbbB9RYvXoySkhLblJ2d7cIqa9UNM2aLKEsNRERE7YGs3UxNVVVVhalTp0IURaxcubLRdTUaDTQajYsqa5i1mwmQAo3Ox6uRtYmIiKil3L5lxhpkMjMzsXXr1kZbZdyJWqWARiXtXp7RRERE5DxuHWasQebs2bPYtm0bQkJC5C6pWXitGSIiIueTtZvJYDAgPT3d9jojIwMpKSkIDg5GVFQU7rvvPhw9ehTfffcdzGYzcnNzAQDBwcFQq9Vyld1kAd5euGowMcwQERE5kaxh5vDhwxg5cqTt9YIFCwAAycnJWLp0KTZt2gQA6N+/v937duzYgREjRriqzBbjLQ2IiIicT9YwM2LECIhiw2f6NLbME7CbiYiIyPncesyMpwvQ8JYGREREzsYw40TWlhk9W2aIiIichmHGiXhLAyIiIudjmHEiDgAmIiJyPoYZJ+IAYCIiIudjmHEirTcHABMRETkbw4wTsWWGiIjI+VoUZrKzs3Hx4kXb64MHD2L+/Pn45JNPHFZYW8ABwERERM7XojDz0EMPYceOHQCA3Nxc/O53v8PBgwfxwgsv4JVXXnFogZ6MA4CJiIicr0Vh5uTJkxg8eDAA4KuvvkKfPn3wyy+/YN26dVizZo0j6/No7GYiIiJyvhaFmaqqKmg0GgDAtm3bcO+99wIAevTogZycHMdV5+Gs3UwGUzUsFs++NQMREZG7alGY6d27N1atWoU9e/Zg69atGDt2LADg8uXLCAkJcWiBnszaMiOKUqAhIiIix2tRmHnjjTfw8ccfY8SIEXjwwQeRmJgIANi0aZOt+4kAby8l1EppF7OriYiIyDladNfsESNG4OrVq9Dr9QgKCrLNnzFjBnx9fR1WXFsQ4K1CQZmpZhCwj9zlEBERtTktapmpqKiA0Wi0BZnMzEysWLECaWlpCA8Pd2iBno6DgImIiJyrRWFmwoQJWLt2LQCguLgYQ4YMwTvvvIOJEydi5cqVDi3Q0wXwKsBERERO1aIwc/ToUdx+++0AgH//+9+IiIhAZmYm1q5di/fff9+hBXo6tswQERE5V4vCTHl5OQICAgAAP/30EyZPngyFQoFbbrkFmZmZDi3Q0zHMEBEROVeLwkzXrl2xceNGZGdnY8uWLbjrrrsAAPn5+dBqtQ4t0NPxlgZERETO1aIw89JLL2HhwoWIi4vD4MGDMXToUABSK81NN93k0AI9HW9pQERE5FwtOjX7vvvuw2233YacnBzbNWYAYNSoUZg0aZLDimsLAjTsZiIiInKmFoUZAIiMjERkZKTt7tkdO3bkBfPqwbOZiIiInKtF3UwWiwWvvPIKdDodOnXqhE6dOiEwMBCvvvoqLBaLo2v0aBwATERE5Fwtapl54YUX8Pe//x2vv/46br31VgDAzz//jKVLl6KyshKvvfaaQ4v0ZBwATERE5FwtCjOfffYZ/va3v9nulg0A/fr1Q4cOHfDUU08xzNRhbZnRs5uJiIjIKVrUzVRYWIgePXpcN79Hjx4oLCxsdVFtCbuZiIiInKtFYSYxMREffvjhdfM//PBD9OvXr9VFtSUcAExERORcLepmevPNNzFu3Dhs27bNdo2Zffv2ITs7Gz/88INDC/R02pqWGYOxGqIoQhAEmSsiIiJqW1rUMnPHHXfgzJkzmDRpEoqLi1FcXIzJkyfjt99+wz//+U9H1+jRrC0zFhEoM5llroaIiKjtEURRFB21sWPHjuHmm2+G2ew+X9p6vR46nQ4lJSWy3GpBFEUkvLAZ1RYR+xbfiSidj8trICIi8jTN+f5uUcsMNZ0gCBwETERE5EQMMy7AQcBERETOwzDjArXXmmHLDBERkaM162ymyZMnN7q8uLi4NbW0WexmIiIicp5mtczodLpGp06dOmH69OlN3t7u3bsxfvx4REdHQxAEbNy40W65KIp46aWXEBUVBR8fH4wePRpnz55tTslugd1MREREztOslpnVq1c79MPLysqQmJiIxx57rN5WnzfffBPvv/8+PvvsM8THx2PJkiUYM2YMTp06BW9vb4fW4kxsmSEiInKeFl00z1GSkpKQlJRU7zJRFLFixQq8+OKLmDBhAgBg7dq1iIiIwMaNG/HAAw/U+z6j0Qij0Wh7rdfrHV94M2nZMkNEROQ0bjsAOCMjA7m5uRg9erRtnk6nw5AhQ7Bv374G37d8+XK7rq+YmBhXlNsotswQERE5j9uGmdzcXABARESE3fyIiAjbsvosXrwYJSUltik7O9updTYFwwwREZHzyNrN5AwajQYajUbuMuxwADAREZHzuG3LTGRkJAAgLy/Pbn5eXp5tmafgdWaIiIicx23DTHx8PCIjI7F9+3bbPL1ejwMHDtju1O0paltmGGaIiIgcTdZuJoPBgPT0dNvrjIwMpKSkIDg4GLGxsZg/fz7+/Oc/IyEhwXZqdnR0NCZOnChf0S1QO2aG3UxERESOJmuYOXz4MEaOHGl7vWDBAgBAcnIy1qxZgz/+8Y8oKyvDjBkzUFxcjNtuuw0//vijR11jBgC0NWHGYGTLDBERkaMJoiiKchfhTM25hbiz5OkrMeQv26FUCEh/LQmCIMhSBxERkadozve3246ZaUv8NVLLjNkioqLKLHM1REREbQvDjAv4qpVQKqTWGA4CJiIiciyGGRcQBMHWOsNBwERERI7FMOMivNYMERGRczDMuAivNUNEROQcDDMuwmvNEBEROQfDjItoebNJIiIip2CYcRHebJKIiMg5GGZcJIAtM0RERE7BMOMiDDNERETOwTDjItZuJj27mYiIiByKYcZF2DJDRETkHAwzLsIBwERERM7BMOMibJkhIiJyDoYZF+F1ZoiIiJyDYcZF2M1ERETkHAwzLlK3m0kURZmrISIiajsYZlzE2jJTbRFRWWWRuRoiIqK2g2HGRfzUSigE6Tm7moiIiByHYcZFBEGAv0bqatJzEDAREZHDMMy4EAcBExEROR7DjAvxWjNERESOxzDjQlpbywzDDBERkaMwzLiQtWXGYGQ3ExERkaMwzLgQu5mIiIgcj2HGhfy9eTYTERGRozHMuBDPZiIiInI8hhkXYjcTERGR4zHMuBBbZoiIiByPYcaFtGyZISIicjiGGRdiNxMREZHjMcy4kLWbKaekAgYjAw0REZEjMMy4UK8oLUL9NbhqMGH++hSYLaLcJREREXk8hhkX8tOo8Mn0AVCrFNiWmoc3t5yWuyQiIiKP59Zhxmw2Y8mSJYiPj4ePjw+6dOmCV199FaLouS0aN8cG4a37+gEAPt51Hl8fzpa5IiIiIs+mkruAxrzxxhtYuXIlPvvsM/Tu3RuHDx/Go48+Cp1Oh3nz5sldXotN6N8B6fkGfPC/dPxpwwnEhfphUFyw3GURERF5JLdumfnll18wYcIEjBs3DnFxcbjvvvtw11134eDBgw2+x2g0Qq/X203u6JnR3ZDUJxJVZhH/759HkF1YLndJREREHsmtw8ywYcOwfft2nDlzBgBw7Ngx/Pzzz0hKSmrwPcuXL4dOp7NNMTExriq3WRQKAe9MTUSfDloUlpnw+GeHeDE9IiKiFhBENx6AYrFY8Kc//QlvvvkmlEolzGYzXnvtNSxevLjB9xiNRhiNRttrvV6PmJgYlJSUQKvVuqLsZskpqcCED/civ9SIkd3D8LfkQVAqBLnLIiIikpVer4dOp2vS97dbt8x89dVXWLduHb744gscPXoUn332Gd5++2189tlnDb5Ho9FAq9XaTe4sSueDT6cPhEalwI60K1j+Q6rcJREREXkUt26ZiYmJwfPPP4/Zs2fb5v35z3/G559/jtOnm3Zac3OSnZy+O34Zc774FQDw+uS+eGBwrMwVERERyafNtMyUl5dDobAvUalUwmKxyFSR89zTLxrzRycAAF7ceBL7zxfIXBEREZFncOswM378eLz22mv4/vvvceHCBWzYsAHvvvsuJk2aJHdpTvH0qATc0y8K1RYRsz4/gsyCMrlLIiIicntu3c1UWlqKJUuWYMOGDcjPz0d0dDQefPBBvPTSS1Cr1U3ahqd0M1lVVplx/8f7cOxiCbqG++Obp4ZBW3NPJyIiovaiOd/fbh1mHMHTwgwA5OkrMeHDvcjVV2J4tzD8I3kgVEq3bkQjIiJyqDYzZqa9itB642/JA+HtpcDuM1fwGs9wIiIiahDDjJvq00GHv07tDwBYvfcC1h3IlLcgIiIiN8Uw48aS+kZh4V3dAEhnOL307UkYjNUyV0VEROReGGbc3OyRXfHIsDiIIrB2XybuencXdpzOl7ssIiIit8Ew4+YEQcDSe3tj3RNDEBvsi8sllXh0zSE8vf5XFBiMN94AERFRG8cw4yFu7RqKLfOH48nb46EQgG9TLmP0u7uw4deLaOMnpBERETWKYcaD+KiVeGFcL2x46lb0iAxAUXkVnvnyGB5dcwgXi8rlLo+IiEgWDDMeKDEmEP+dexueG9MdaqUCO9Ou4K6/7saavRkwW9hKQ0RE7QvDjIfyUiowe2RX/PD07RgUF4RykxlL/3sKv1/1C87mlcpdHhERkcswzLSGuUruCtA13B9fzhiKVyf2gb9GhaNZxRj3/s94b9tZmKrb3g05iYiIrsUw01IXjwB/7QPsXwVUVcpaikIh4OFbOmHrguEY1SMcJrMFf912BuM/+BmHLhTKWhsREZGzMcy01OG/A4Zc4MdFwPv9gQOfyB5qonQ++FvyQHzw4E0I8VMjLa8Uv1+1D89+dQxXeRo3ERG1UbzRZEtVm4CUdcCed4CSbGleQDRw+wLg5umASuO4z2qBojIT3txyGusPZUMUgQBvFZ4b0x3ThnSCUiHIWhsREdGN8K7ZdTj9rtnVRuDXz6VQo78kzdN2kELNTQ/LHmp+zSrCkm9P4uQlPQCgd7QWr07sg5tjg2Sti4iIqDEMM3U4PcxYVRuBX/8J7Hm3TqjpWBNq/iBrqDFbRHxxMAtv/Xga+krp3k4PDIrBH8f2QLCfWra6iIiIGsIwU4fLwoxVtRE4ulZqqSnNkeZpOwLDnwX6/wFQyRcerhqMeH3zafz7yEUAgM7HC38c2x0PDIpl1xMREbkVhpk6XB5mrKoqgaOfSS01hlxpni4GuP1ZoP80WUPN4QuFWPLtb0jNkbqeEjvq8OrEPujXMVC2moiIiOpimKlDtjBjVVUJHFkD/PwuYMiT5ql8gI4DgZghQOwtQMdBgE+gS8uqNlvwz/2ZePenMyg1VkMQgIcGx+K5Md0R6MuuJyIikhfDTB2yhxmrqgop1Ox9r7b7yUYAwnvWhpuYIUBQHCA4v+snv7QSy384jQ2/SuN8gny9MH90N9w/KAbeXkqnfz4REVF9GGbqcJswY2WxAFfPANn7gawD0mPh+evX84+oCTdDgdghQGQ/QOnltLIOnC/Akm9P4kyeAQAQpfPGUyO7YurAjtCoGGqIiMi1GGbqcLswUx9DPpC1H8g+ID3mHAMs19wqQVACgTFSi019k0/rT7WuMluw/lA2/m9HOnJKpAsAdgj0wZw7u+K+AR3hpeQ1FomIyDUYZurwiDBzraoK4NJR+9abypLG3+Otqz/kBHeWBh4rmt66UlllxpeHsvHRjnTkl0pXDu4Y5IN5dyZg0s0dGGqIiMjpGGbq8Mgwcy2LRTojqujC9VNhBlCW3/j7FV5AUCcp2Fw7BcY22H1VWWXGFwey8H87z9luhxAb7It5oxIwsX80VAw1RETkJAwzdbSJMHMjpjKgKLOeoHMeKM4EzKaG32vtvqobcEISgNAEKegolKgwmbHuQCZW7jyHgjJpW/Ghfpg3qivuTezAa9QQEZHDMczU0S7CTGMsZumKxIUZUrixTTWvqysafq/KGwjpCoR2A0K7wRjUFZsu+ePdI2bklEsBpkuYH+aNSsA9/aIZaoiIyGEYZupo92GmMaIIlOZeE3LOAVfPAgXpDbboiBCg947G8cpwnK6OQrrYASZtJ9x5y0DcNfRmaNTy3o+KiIg8H8NMHQwzLWQxS11UV85Ip5JfTZNCzpU0oLK4wbdVQ4EKTTh8wuOhCo6TBh8HxtZO2g6yXv2YiIg8A8NMHQwzDiaKQNnVmnBzBrhyBtX5aSjLTYdPxWWoUX2DDQiANloKNsGdpevnRPcHIvsCaj9X/AREROQBGGbqYJhxHVNVNbYcOI6ffjkEoTgLHYSriFVcxc06PeJVBVAbLgHVlQ28W5DG5kT3B6L6A1GJQFQ/QBPgwp+AiIjcBcNMHQwzrmexiPjf6Xys2nUOhzOLAEh3ZrirZzjmDNGhr5++tgsrJ0W6SOB1t3gAAAEI6VIbbqL7Sy05Lr6PFRERuR7DTB0MM/I6fKEQq3adx7bUPNu8wfHBmHVHF4zoHgbBev+p0rzaYHO55lF/sf6NegdKp5PraqbAuo+xgF+oS+5rRUREzsMwUwfDjHtIzy/Fx7vOY2PKJVSZpUOue0QAZo7ojHv6Rdd/VWHDFSnU5KTUBp3irBt/mMob0HW0Dzj+YYBPMOAbUjMFS7eAaO79rqqN0hlgpblA6eWaxxxAnyM9VhsBXYeaz4+1D1reuuZ9VnsgikBRBnDxsBRiVWr7QeO6GEDtK3eVrlOUCaRuAsoLgPBeQEQf6ZpPTrwvG5G7Ypipg2HGveSWVOIfezPwxYEsGIzSYOEOgT548vZ4TB0UA1+1qvENGEuB4mygpGYqvuaxNBdAMw5pjU4KNtaA4xtSE3qCpVPT9Zftw0t5Qct/eI3umlakmkf/SOl6P8ZSwGioeSwFjPo6z+tMppr1dB2kLjjrOKOI3oDKzU+LryyRbtVx8TBw8RBw6fCN96lviH0wDbw2JAZ6dktcySXg1Ebg5DfS/riWUg2E9ZAGyUf0kX7PkX2lY5TsleYCF36WbglTr0b+b9BGAx0GshvbjbSpMHPp0iUsWrQImzdvRnl5Obp27YrVq1dj4MCBTXo/w4x7Kqmowuf7M7F6bwauGqTr2QT5euGRYfGYPrQTgvxaePp2tUnqniq5aB96ygqkL82KwprHYjQr9NSl1AABkUBAFKCNkh6tk0pt/9nFWdJjRVHLPqs5FF5AeM/acBPdHwjvDXh5t2x75iqgUi8FLaVGCkoqb6mVoCnhwWIGrpyWQsvFw9J05TSu2+9KtTQmqsMAQLRI+86634z6G3+O2r/O7yO6zmMkEBAt/Y78I5rfumExS1fXriqXHs0m6dIC3g74f6Q0Dzj1LfDbN0DWvjoLBCDuNqk1Ju8UkPebFF7rExANRPaRAk5kHyC0u9SKZftdaaTnTf19OVNprrQPg+IBhQNvg2IxA5d/Bc5sAc5ukVpvW0WQ/g3FDJGm2CFSzXLvv7rM1dL/YeVXpTNLy2v+byu7ev08laYm/HeSHoPials9vXzk/kluqM2EmaKiItx0000YOXIkZs2ahbCwMJw9exZdunRBly5dmrQNhhn3Vlllxr+PXMQnu88jq7AcAODjpcQDg2PwxO2d0SHQSf/gLGYp0JRfE3LKC4DyQmlSetl/KQZESq99gpr/n5vRUBOsLtZ+UVsDjyEP8PKTzty6btLWP8/LGyg4J3W/XU6RHusLTAoVENYTiE6UAo5fqNQ6UlkiBRXb83qmqrIGfhhBCjXWcGN7VNc8ekv7N/c4YDJc//bATkDHQUDHgdJjZN+GW5Qqiq9pgcuy33/lV5v4CxAA//Da36VPkBTSTDVBpapMem4NLqYywGysf1MB0VLYCOtuuzo2QrtJ227suCgrAFK/lVpgMvdKwc0qdijQezLQawIQEFE732KRBsvnnQRyT0qPeSel25U0h8q7JuSo7cOO9SrfkX2lswcj+7W+xafaCOSeALIP1gTZQ9LvCwDUAbWD+aNvkqbgzs3791RRBKRvB85uBdK3Xt+yF5UotXY2pL7PEi3SdbSKMq5f5hdWG25ihki136gFtKpSasm1dj/buqIvS2FDtEhdrNKH1zyI1zyvu8xS+/9VI9f5ahb/iGuCTs2jX5j0R2F15TWTUWrxqjZeP7+6Euj6O6DnPY6prUabCTPPP/889u7diz179rR4GwwznqHabMHmk7lYufMcTuVIf42rFAIm9O+AmXd0RkIET9FulChKX/J1w83lFCmktZbCC7BUtey9an/pC6vjoNoA4x/e+pqsTOU1XYHWL4zL13x51EyWG13/qBGCQgqbCmXjXyQarRRyQrvXhp2geODSEakF5vwuQDTXrt9hINBnMtBrotRl2ByVeiD/lBQarEGnKKP2i6U1P6+2Y51w01cKOIGxDQeOkkvAxYNSy1v2Qal15NogKCikFrj6Ls3grasNNtZJF1P7eaIo/axntkgBJvuA/X7UaIEuI4GEMUDC71p3fJXmST9L9gEg64D07+jaK6Er1VKNMYOllo7SvNrxc9bA4vSWWEEK5H6hgG8o4BdS8xha02VeM6+qUgrDRZk1fwjUPG+ota81bnsGGL3UoZtsM2GmV69eGDNmDC5evIhdu3ahQ4cOeOqpp/Dkk082+B6j0QijsfYfkl6vR0xMDMOMhxBFEXvOXsXKneew73ztX1yje4Zj1oguGNCJ4wSaTBSlliBbwDkmtZR4B0pfII1OWmk9jRZQqqQWArPJ/i8x66PZdP1faRYLENFLGuuhUMq7HywW6S9a21/Kl6W/cr18pW4ZtZ8UVtS+NY91n/tKrRfWL9aKIuBqut1FI3H1jBQk6ra0NCQqUWqB6T1J+kvYmT+z2Vjz+zDWPDddP89oAK6kSqEo53j9LROAdExE9qsdt1NRKLW4ZB+S9ue1fEPqBNhBQIebAZWPtN8u/1o75Z6o/7YpviFSYPCPkELgtWc2hvUAEu6SpthbnDdAuqpS+veTfUAKaln7m94aqPK+puszSmrV8w+v82+i5riyBcW6r69Z5q2rDSw+QS3/dyWK0nFcXBNwrg06FUX2La5e3te0wHrXM99HCned72hZTQ1oM2HG21vq61+wYAF+//vf49ChQ3j66aexatUqJCcn1/uepUuXYtmyZdfNZ5jxPCnZxVi18xy2nMq1tboOigvC1IExGNMnElpvnuFBbqLaKN3b7ErNbT+sYafgvNSq0WeSFGJCmtY9LptKfU1LT024yT0O5Kc23jInKKUxOx0HAR0HS61vTe06qjZJYapuwMn77fqWJZU3ED+8NsA4Mwg2RhSl33P2ASnYlF25phs6qnaclqcPTHcDbSbMqNVqDBw4EL/88ott3rx583Do0CHs27ev3vewZabtOXfFgE92ncc3v160ndatVilwZ/dwTOgfjZE9wuHtJfNf/0RtVbVJCmc5x2u7tTRaIKYmvET3d+ytSKoqgfzfpGBTckkaTxR3W/s6RZ8ANC/M3OA8WHlFRUWhV69edvN69uyJ//znPw2+R6PRQKNx89NTqVm6hPnjjfv64ZnfdcNXh7Ox6dhlpOcb8ONvufjxt1z4a1QY0zsSE/pHY1iXEKjqu2YNEbWMSl0zdqavaz7Py1s6s63DANd8HrUJbh1mbr31VqSlpdnNO3PmDDp1kqmJkWQVqfPGvFEJmHtnV6TmlOLbY5fw3bEcXCquwH+OXsR/jl5EqL8a4/pG4d7+0bg5Nqj2CsNERNRmuXU306FDhzBs2DAsW7YMU6dOxcGDB/Hkk0/ik08+wbRp05q0DZ7N1LZZLCKOZBXh25RL+OFELgrLagcTdgzywb2J0bi3fzR6RPJ3T0TkSdrMmBkA+O6777B48WKcPXsW8fHxWLBgQaNnM12LYab9qDJb8HP6Vfw35TK2/JaLMlPt6Zt9O+jwh1ticW9iB/ioOb6GiMjdtakw01oMM+1ThcmM/53Ox7cpl7Az7QpMZum02QBvFabc3BF/uKUTuob7y1wlERE1hGGmDoYZKiwz4evD2Vh3IMt2lWEAuKVzMB6+JQ539Y6o/0aXREQkG4aZOhhmyMpiEbH77BV8vj8L/zudB0vNkR8WoMEDg2Lw4OBYRDvr9glERNQsDDN1MMxQfS4VV2D9wSysP5SNK6XSdYkUAnBnjwj84ZZYDE8Ig0LBM6GIiOTCMFMHwww1pspswU+/5eGf+y9g//na+xjFBvvivgEdMbpnBHpGBfAUbyIiF2OYqYNhhpoqPb8Un+/Pwn+OXkRpZe3l1KN13rizZzhG9YjA0C4hvNowEZELMMzUwTBDzVVuqsZ3x3Pw0295+Dn9Ciqram8g6OOlxK1dQzGqZzju7BGOCK23jJUSEbVdDDN1MMxQa1RWmbHvXAG2n87D9tR85JRU2i3v20GHUTWtNn06aNkdRUTkIAwzdTDMkKOIoojUnFJsT83D9tP5OHaxGHX/9URoNbizRwTG9Y3CLZ2DeY8oIqJWYJipg2GGnOVKqRE70vLxv9R87Dl7xe6Kw6H+aoztE4l7+kVjUFwwlDwzioioWRhm6mCYIVcwVptx4HwhNp/MxY8nc1BUXmVbFh6gwd19o3BPvyjcHBvEU76JiJqAYaYOhhlytSqzBfvOFeC745fx48lc6OucGRWl87YFm/4xgRxjQ0TUAIaZOhhmSE6magt+Tr+C747l4KdTeTAYa4NNh0Af3NMvCuP6RaF3tI5dUUREdTDM1MEwQ+6issqM3Weu4LvjOdiWmofyOmNs/DUq9O2gQ2JMIPrHBOKm2ECe9k1E7RrDTB0MM+SOKqvM2HE6H98dz8HOtHy7wcNWkVpv9I8JRP/YQCR2DES/jjr4aVQyVEtE5HoMM3UwzJC7M1tEnM0vRUpWMY5dLMavWcU4k1dquxGmlUIAEsIDbAHnls4hiA/1k6doIiInY5ipg2GGPFGZsRonL5UgJVsKOClZxbh8zQX7AKBTiC9GdAvDHd3DMLRzKHzUvNUCEbUNDDN1MMxQW5Gvr0RKdjFSsotxJLMIR7OKUGWu/eerVikwJD4Yd3QLw4ju4egS5sezpYjIYzHM1MEwQ22VwViNX9KvYueZK9iVdgWXiivslncM8sGI7mG4o1s4hnUJ4XgbIvIoDDN1MMxQeyCKIs5dMWBn2hXsOnMFB84XwmSuvUGmWqnAoPgg3J4QhiHxwejTQQcv3m6BiNwYw0wdDDPUHpWbqrHvXAF2nbmCnWlXkFVYbrfcV63EgE5BuKVzCAbHB6NfRx00Ko63ISL3wTBTB8MMtXeiKCLjahl2nbmCfecKcPBCIYrr3G4BADQqBW6ODcKQzsEYEh+Cm2ID4e3FcENE8mGYqYNhhsiexSLiTH4pDpwvxIGMAhw4X4iCMpPdOmqlAokxOgyJD8HAuCD0iNQiQqvhgGIichmGmToYZogaZx1vs/98IQ5kFOLA+QLklxqvW0/rrUK3iAAkRASgW4R/zXN/hPkz5BCR4zHM1MEwQ9Q8oijiQkE5DpwvwIGMQhy7WIzMgnKYr72KX41AXy90C5eCjTXgdIsIQIifmiGHiFqMYaYOhhmi1jNWm3H+ShnO5JXWTAaczStFZmE5GvofxFetRHSgD6IDfdAh0Acdg3wQHeiNDoG+iA70RqTWGyqeUUVEDWjO9zcvPEFEN6RRKdEzSoueUfb/oVRWmZGeb8DZ/NqAcybPgOyicpSbpGXp+YZ6t6lUCIjUetcEHCn0dAnzR/fIAHQN9+cAZCJqMrbMEJHDVVaZkVNSicvFFbhUVIGLxRW255eKK5BTUmF39eJrKRUC4kP90CMyoGbSontkADoG+bDriqidYDdTHQwzRO7HYhFxxWDEpToB52JROc7mGXA6txQlFVX1vi9Ao0I3W8AJQI8oLbqFB0Dn6+Xin4CInI1hpg6GGSLPIooi8vRGpObqkZZbirTcUqTm6HHuiqHB1pwgXy/Eh/ohPtQf8aG+NY9+iAv1ha+avelEnohhpg6GGaK2ocpswfkrZTidq8fpmpBzOkdf793E64rUeiOuJuB0DvVDXKgfuob7Iy7El11WRG6MYaYOhhmitq3cVI0LV8uRcbUMGVcNyLhaXvNYhqLy+rurACDYT42BnYIwKC4YA+OC0DtaB7WKZ1cRuQuGmToYZojar+JyU03IKcOFq2U4f7UMFwrKcDbPAGO1xW5dby8F+scE1oSbYNwcG4gAb47FIZILw0wdDDNEdC1TtQUnL5fg8IVCHLpQhMMXCq9rxVEIQI9ILQbFBWFgTetNpNabXVNELsIwUwfDDBHdiHRLhzIcvlCIgxcKcfhC0XV3GgcAL6WAUH8NQv01CAvQIMxfg9AANcL8NQgL8Eaov1qaH6CBv0bF4EPUCm02zLz++utYvHgxnn76aaxYsaJJ72GYIaKWyNNX4vCFIhy6UIjDmYU4dVmPBu7oUC+NSoGwAA06BkkXA+wS5o/OYX7oEuaPDoE+UCgYdIga0yavAHzo0CF8/PHH6Nevn9ylEFE7EKH1xrh+URjXLwqA1DVVUGbEldLa6aqh5rnB+tqEK6VGGIzVMFZbcLGoAheLKrD/fKHdtjUqBeJD/dAl3B9dah47h0phx0/jMf8tE7kNj/hXYzAYMG3aNHz66af485//LHc5RNQOqVUKROl8EKXzueG6FSYzrhqMyNNXIrOgHOevGnAuvwznrxpw4Wo5jNUWnM4txenc0uvea73Fg59GBT+1Cr4aJfzUqprXSvhe+6hWwU+jRJCvmldIpnbLI8LM7NmzMW7cOIwePfqGYcZoNMJoNNpe6/V6Z5dHRGTHR61ETLAvYoJ9MTAu2G5ZtVlqsakbcKyPVw0m5Oorkatv/No5DQny9cKATkEY0CkYAzoFoV9HHe9xRe2C24eZ9evX4+jRozh06FCT1l++fDmWLVvm5KqIiFpGpVQgrubifXf2sF9WUl6F9CsGXCmtRLnJjDKTGeXGapQZq6XnpmqUGa95rFnnapkJReVV2Jaaj22p+QCkAcu9o3UY2CmoJuQEIVzrLcNPTeRcbj0AODs7GwMHDsTWrVttY2VGjBiB/v37NzgAuL6WmZiYGA4AJqI2zVRtwW+XS3AkswhHMotwOLMIV0qN160XE+yDAbFBGBAXjJtiAhHo6wWlQpAmQYBKoYBCAbt5SoXA7ityuTZzNtPGjRsxadIkKJW1zaRmsxmCIEChUMBoNNotqw/PZiKi9kgURVwsqsDhzEIp3FwoQlpeKVr6P75CgC3ohPhp0DnMr+Z+WNLUOdQfHYJ8oORZWuQgbSbMlJaWIjMz027eo48+ih49emDRokXo06fPDbfBMENEJCmtrMKvWcW21psTl0pQWWWGRRRRbRFbHHSs1EoFYkN8a8JNnbAT5ocwfw1bd6hZ2syp2QEBAdcFFj8/P4SEhDQpyBARUa0Aby8M7xaG4d3C6l1usYgwiyLMFtEWcCyW2kezKKLaLCJXX4mMK9LtIaz3wbpQUA5TtQXp+Qak5xuu27a3lwIhfhqE+qsR6q9BiL8aIf4ahPjVvrY+BvuqoVLyPlnUdG4dZoiIyHUUCgEKCLjRCVAxwb4YdM1ZWmaLiMvFFbZ7YWVcrQ07F4sqUFllwaXiClwqrmhSLUG+Xgj2U0Pr4wWttxcCvFXQ+tQ8entB661CgLcXtD7So22+jxf8ea2edsetu5kcgd1MRETyMlabkVdixNUyIwoMJhQYjCgoM+GqQbrQYIGhZn6ZEYVlpmZdabk+gb5eiAup09UV5oe4EOk5L0roOdpMNxMREXk+jUqJ2BBfxIb43nBds0VEcblJCjllRpRWVkNfUYXSymrpeWUVSiuroK+oRqmx5rGyyrasyiyiuLwKKeXFSMkuvm77EVqN3cDl+FB/xIf6IcRPDS+VAl5KAV4KBW834WEYZoiIyG0oFYI0lsZfAyCgWe8VRRHlJjOyCsvturusU2GZCXl6I/L0xutuMXEtlUKAl1IKN2qVAl5KBVRKaZ5aKb328VIi2E+NID81QvzUCG5g4oULnY9hhoiI2gRBEOCnUaFnlBY9o67vligpr0JGQc2g5StlyCgotz0vM5nt1q22iKi2mFFR1fq6/NRKu8AT5CsFoCBfr5pHNQJrxghZn2tUDEDNwTBDRETtgs7XC/19A9E/JvC6ZWaLiCqzBSazBVXVFlSZa19Xm+tfVmaqRlGZCQVlJhQ2MFVbRJSZzCgzSTcdbSprALKGG1+1EmqVEmqlAmqVApqaSa2SWoo0XoqaZUrb8lB/DbpF+Ne0crVtDDNERNTuSVc8Vjq0S0gURZQaq1FokAJPUU3AKSo3obDchOKyKumxXJpfXF6FonJpAHRLAlBDgv3USAj3R0KEP7pFBKBruPQY4qduM9f+4dlMREREbsJiEVFaWY3Ccin0FNXcc6uyygxTtQXGagtM1RaYzNe8rrbAaLbAWCW1IBmrzMgpqUR2UXmDF0MM8vVCQkQAEmrCTUK4PzoG+UIQAFEERIg1j1Iws25G2l7dZVJgCgtwbAsQz2YiIiLyQAqFAJ2vF3S+XoiHX6u3V2Ey49wVA87kleJsvgFnax6zCstRVF6FgxmFOJjR+GDopnhqRBf8cWyPG6/oJAwzREREbZSPWok+HXTo00FnN98acs7ml+JsngFn8gxIzy9Frr4SACBAgCAAAqSB1YI0s/b1Nct81fIOWGaYISIiamcaCjmeije/ICIiIo/GMENEREQejWGGiIiIPBrDDBEREXk0hhkiIiLyaAwzRERE5NEYZoiIiMijMcwQERGRR2OYISIiIo/GMENEREQejWGGiIiIPBrDDBEREXk0hhkiIiLyaAwzRERE5NFUchfgbKIoAgD0er3MlRAREVFTWb+3rd/jjWnzYaa0tBQAEBMTI3MlRERE1FylpaXQ6XSNriOITYk8HsxiseDy5csICAiAIAgO3bZer0dMTAyys7Oh1Wodum1Pwv0g4X6oxX0h4X6QcD9IuB9qNWVfiKKI0tJSREdHQ6FofFRMm2+ZUSgU6Nixo1M/Q6vVtvsDE+B+sOJ+qMV9IeF+kHA/SLgfat1oX9yoRcaKA4CJiIjIozHMEBERkUdjmGkFjUaDl19+GRqNRu5SZMX9IOF+qMV9IeF+kHA/SLgfajl6X7T5AcBERETUtrFlhoiIiDwawwwRERF5NIYZIiIi8mgMM0REROTRGGZa6KOPPkJcXBy8vb0xZMgQHDx4UO6SXG7p0qUQBMFu6tGjh9xlOd3u3bsxfvx4REdHQxAEbNy40W65KIp46aWXEBUVBR8fH4wePRpnz56Vp1gnutF+eOSRR647PsaOHStPsU60fPlyDBo0CAEBAQgPD8fEiRORlpZmt05lZSVmz56NkJAQ+Pv7Y8qUKcjLy5OpYudoyn4YMWLEdcfEzJkzZarYeVauXIl+/frZLgg3dOhQbN682ba8PRwPwI33gyOPB4aZFvjyyy+xYMECvPzyyzh69CgSExMxZswY5Ofny12ay/Xu3Rs5OTm26eeff5a7JKcrKytDYmIiPvroo3qXv/nmm3j//fexatUqHDhwAH5+fhgzZgwqKytdXKlz3Wg/AMDYsWPtjo9//etfLqzQNXbt2oXZs2dj//792Lp1K6qqqnDXXXehrKzMts4zzzyD//73v/j666+xa9cuXL58GZMnT5axasdryn4AgCeffNLumHjzzTdlqth5OnbsiNdffx1HjhzB4cOHceedd2LChAn47bffALSP4wG48X4AHHg8iNRsgwcPFmfPnm17bTabxejoaHH58uUyVuV6L7/8spiYmCh3GbICIG7YsMH22mKxiJGRkeJbb71lm1dcXCxqNBrxX//6lwwVusa1+0EURTE5OVmcMGGCLPXIKT8/XwQg7tq1SxRF6ffv5eUlfv3117Z1UlNTRQDivn375CrT6a7dD6IoinfccYf49NNPy1eUjIKCgsS//e1v7fZ4sLLuB1F07PHAlplmMplMOHLkCEaPHm2bp1AoMHr0aOzbt0/GyuRx9uxZREdHo3Pnzpg2bRqysrLkLklWGRkZyM3NtTs+dDodhgwZ0i6Pj507dyI8PBzdu3fHrFmzUFBQIHdJTldSUgIACA4OBgAcOXIEVVVVdsdEjx49EBsb26aPiWv3g9W6desQGhqKPn36YPHixSgvL5ejPJcxm81Yv349ysrKMHTo0HZ7PFy7H6wcdTy0+RtNOtrVq1dhNpsRERFhNz8iIgKnT5+WqSp5DBkyBGvWrEH37t2Rk5ODZcuW4fbbb8fJkycREBAgd3myyM3NBYB6jw/rsvZi7NixmDx5MuLj43Hu3Dn86U9/QlJSEvbt2welUil3eU5hsVgwf/583HrrrejTpw8A6ZhQq9UIDAy0W7ctHxP17QcAeOihh9CpUydER0fj+PHjWLRoEdLS0vDNN9/IWK1znDhxAkOHDkVlZSX8/f2xYcMG9OrVCykpKe3qeGhoPwCOPR4YZqjFkpKSbM/79euHIUOGoFOnTvjqq6/w+OOPy1gZuYMHHnjA9rxv377o168funTpgp07d2LUqFEyVuY8s2fPxsmTJ9vF2LHGNLQfZsyYYXvet29fREVFYdSoUTh37hy6dOni6jKdqnv37khJSUFJSQn+/e9/Izk5Gbt27ZK7LJdraD/06tXLoccDu5maKTQ0FEql8rqR53l5eYiMjJSpKvcQGBiIbt26IT09Xe5SZGM9Bnh8XK9z584IDQ1ts8fHnDlz8N1332HHjh3o2LGjbX5kZCRMJhOKi4vt1m+rx0RD+6E+Q4YMAYA2eUyo1Wp07doVAwYMwPLly5GYmIj33nuv3R0PDe2H+rTmeGCYaSa1Wo0BAwZg+/bttnkWiwXbt2+36wdsjwwGA86dO4eoqCi5S5FNfHw8IiMj7Y4PvV6PAwcOtPvj4+LFiygoKGhzx4coipgzZw42bNiA//3vf4iPj7dbPmDAAHh5edkdE2lpacjKympTx8SN9kN9UlJSAKDNHRP1sVgsMBqN7eZ4aIh1P9SnVceDQ4YRtzPr168XNRqNuGbNGvHUqVPijBkzxMDAQDE3N1fu0lzq2WefFXfu3ClmZGSIe/fuFUePHi2GhoaK+fn5cpfmVKWlpeKvv/4q/vrrryIA8d133xV//fVXMTMzUxRFUXz99dfFwMBA8dtvvxWPHz8uTpgwQYyPjxcrKipkrtyxGtsPpaWl4sKFC8V9+/aJGRkZ4rZt28Sbb75ZTEhIECsrK+Uu3aFmzZol6nQ6cefOnWJOTo5tKi8vt60zc+ZMMTY2Vvzf//4nHj58WBw6dKg4dOhQGat2vBvth/T0dPGVV14RDx8+LGZkZIjffvut2LlzZ3H48OEyV+54zz//vLhr1y4xIyNDPH78uPj888+LgiCIP/30kyiK7eN4EMXG94OjjweGmRb64IMPxNjYWFGtVouDBw8W9+/fL3dJLnf//feLUVFRolqtFjt06CDef//9Ynp6utxlOd2OHTtEANdNycnJoihKp2cvWbJEjIiIEDUajThq1CgxLS1N3qKdoLH9UF5eLt51111iWFiY6OXlJXbq1El88skn22Tgr28fABBXr15tW6eiokJ86qmnxKCgINHX11ecNGmSmJOTI1/RTnCj/ZCVlSUOHz5cDA4OFjUajdi1a1fxueeeE0tKSuQt3Akee+wxsVOnTqJarRbDwsLEUaNG2YKMKLaP40EUG98Pjj4eBFEUxea35xARERG5B46ZISIiIo/GMENEREQejWGGiIiIPBrDDBEREXk0hhkiIiLyaAwzRERE5NEYZoiIiMijMcwQERGRR2OYIaJ2QRAEbNy4Ue4yiMgJGGaIyOkeeeQRCIJw3TR27Fi5SyOiNkAldwFE1D6MHTsWq1evtpun0WhkqoaI2hK2zBCRS2g0GkRGRtpNQUFBAKQuoJUrVyIpKQk+Pj7o3Lkz/v3vf9u9/8SJE7jzzjvh4+ODkJAQzJgxAwaDwW6df/zjH+jduzc0Gg2ioqIwZ84cu+VXr17FpEmT4Ovri4SEBGzatMm2rKioCNOmTUNYWBh8fHyQkJBwXfgiIvfEMENEbmHJkiWYMmUKjh07hmnTpuGBBx5AamoqAKCsrAxjxoxBUFAQDh06hK+//hrbtm2zCysrV67E7NmzMWPGDJw4cQKbNm1C165d7T5j2bJlmDp1Ko4fP467774b06ZNQ2Fhoe3zT506hc2bNyM1NRUrV65EaGio63YAEbWc4272TURUv+TkZFGpVIp+fn5202uvvSaKoigCEGfOnGn3niFDhoizZs0SRVEUP/nkEzEoKEg0GAy25d9//72oUCjE3NxcURRFMTo6WnzhhRcarAGA+OKLL9peGwwGEYC4efNmURRFcfz48eKjjz7qmB+YiFyKY2aIyCVGjhyJlStX2s0LDg62PR86dKjdsqFDhyIlJQUAkJqaisTERPj5+dmW33rrrbBYLEhLS4MgCLh8+TJGjRrVaA39+vWzPffz84NWq0V+fj4AYNasWZgyZQqOHj2Ku+66CxMnTsSwYcNa9LMSkWsxzBCRS/j5+V3X7eMoPj4+TVrPy8vL7rUgCLBYLACApKQkZGZm4ocffsDWrVsxatQozJ49G2+//bbD6yUix+KYGSJyC/v377/udc+ePQEAPXv2xLFjx1BWVmZbvnfvXigUCnTv3h0BAQGIi4vD9u3bW1VDWFgYkpOT8fnnn2PFihX45JNPWrU9InINtswQkUsYjUbk5ubazVOpVLZBtl9//TUGDhyI2267DevWrcPBgwfx97//HQAwbdo0vPzyy0hOTsbSpUtx5coVzJ07Fw8//DAiIiIAAEuXLsXMmTMRHh6OpKQklJaWYu/evZg7d26T6nvppZcwYMAA9O7dG0ajEd99950tTBGRe2OYISKX+PHHHxEVFWU3r3v37jh9+jQA6Uyj9evX46mnnkJUVBT+9a9/oVevXgAAX19fbNmyBU8//TQGDRoEX19fTJkyBe+++65tW8nJyaisrMRf//pXLFy4EKGhobjvvvuaXJ9arcbixYtx4cIF+Pj44Pbbb8f69esd8JMTkbMJoiiKchdBRO2bIAjYsGEDJk6cKHcpROSBOGaGiIiIPBrDDBEREXk0jpkhItmxt5uIWoMtM0REROTRGGaIiIjIozHMEBERkUdjmCEiIiKPxjBDREREHo1hhoiIiDwawwwRERF5NIYZIiIi8mj/Hx2NGdnvJkEdAAAAAElFTkSuQmCC\n"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, BatchNormalization\nfrom keras.regularizers import l2\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport numpy as np\nimport pandas as pd\n\n# Load and preprocess your data\ndf = pd.read_csv('/kaggle/input/main-dataset/Sampling_data.csv')\ndf['Drug Name'] = df['Drug Name'].astype('category').cat.codes\ndf['condition'] = df['condition'].astype('category').cat.codes\n\n# TF-IDF for the 'review' column\ntfidf = TfidfVectorizer(stop_words='english', max_features=200)\nreview_features = tfidf.fit_transform(df['review']).toarray()\nreview_df = pd.DataFrame(review_features, columns=tfidf.get_feature_names_out())\ndf = pd.concat([df, review_df], axis=1)\ndf.drop(columns=['review'], inplace=True)\n\n# Features and target\nfeatures = ['Drug Name', 'condition', 'usefulCount'] + list(review_df.columns)\ntarget = 'rating'\n\n# Split the data\nX = df[features].values\ny = df[target].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Feature Scaling\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Define and compile the neural network with regularization and batch normalization\nmodel = Sequential()\nmodel.add(Dense(512, input_dim=X_train_scaled.shape[1], activation='relu', kernel_regularizer=l2(0.001)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))  # Increased dropout rate\nmodel.add(Dense(256, activation='relu', kernel_regularizer=l2(0.001)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))  # Increased dropout rate\nmodel.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))  # Increased dropout rate\nmodel.add(Dense(1))  # Output layer for regression (rating prediction)\n\n# Compile model with Adam optimizer and a lower learning rate\nmodel.compile(optimizer='adam', loss='mse')\n\n# Early stopping callback to prevent overfitting and reduce learning rate on plateau\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n\n# Train the model\nhistory = model.fit(X_train_scaled, y_train, epochs=100, batch_size=64, validation_data=(X_test_scaled, y_test),\n                    verbose=1, callbacks=[early_stopping, reduce_lr])\n\n# Evaluate the model\nloss = model.evaluate(X_test_scaled, y_test)\nprint(f\"Test Loss: {loss}\")\n\n# Predict and calculate RMSE\ny_pred = model.predict(X_test_scaled)\nrmse = np.sqrt(((y_pred - y_test) ** 2).mean())\nprint(f\"RMSE: {rmse}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T21:30:48.964020Z","iopub.execute_input":"2025-01-30T21:30:48.964443Z","iopub.status.idle":"2025-01-30T21:33:56.934693Z","shell.execute_reply.started":"2025-01-30T21:30:48.964408Z","shell.execute_reply":"2025-01-30T21:33:56.933720Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: 30.9182 - val_loss: 8.0565 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 9.5791 - val_loss: 7.8425 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 8.6016 - val_loss: 7.7070 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 8.1325 - val_loss: 7.6134 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.9466 - val_loss: 7.4744 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.6361 - val_loss: 7.4430 - learning_rate: 0.0010\nEpoch 7/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.5141 - val_loss: 7.3496 - learning_rate: 0.0010\nEpoch 8/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.1941 - val_loss: 7.3372 - learning_rate: 0.0010\nEpoch 9/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.0909 - val_loss: 7.3252 - learning_rate: 0.0010\nEpoch 10/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.8481 - val_loss: 7.2493 - learning_rate: 0.0010\nEpoch 11/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.7534 - val_loss: 7.2811 - learning_rate: 0.0010\nEpoch 12/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.6017 - val_loss: 7.3210 - learning_rate: 0.0010\nEpoch 13/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.5153 - val_loss: 7.2938 - learning_rate: 0.0010\nEpoch 14/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.3508 - val_loss: 7.3431 - learning_rate: 0.0010\nEpoch 15/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.3246 - val_loss: 7.2486 - learning_rate: 0.0010\nEpoch 16/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.2859 - val_loss: 7.3704 - learning_rate: 0.0010\nEpoch 17/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.1845 - val_loss: 7.3140 - learning_rate: 0.0010\nEpoch 18/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.1633 - val_loss: 7.4162 - learning_rate: 0.0010\nEpoch 19/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.0968 - val_loss: 7.3537 - learning_rate: 0.0010\nEpoch 20/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.9938 - val_loss: 7.3885 - learning_rate: 0.0010\nEpoch 21/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.7998 - val_loss: 7.1773 - learning_rate: 5.0000e-04\nEpoch 22/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.4471 - val_loss: 7.1549 - learning_rate: 5.0000e-04\nEpoch 23/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.2868 - val_loss: 7.1732 - learning_rate: 5.0000e-04\nEpoch 24/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.2490 - val_loss: 7.1192 - learning_rate: 5.0000e-04\nEpoch 25/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.1025 - val_loss: 7.0565 - learning_rate: 5.0000e-04\nEpoch 26/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.0065 - val_loss: 6.9731 - learning_rate: 5.0000e-04\nEpoch 27/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.9202 - val_loss: 7.0662 - learning_rate: 5.0000e-04\nEpoch 28/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.9053 - val_loss: 7.0342 - learning_rate: 5.0000e-04\nEpoch 29/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.8199 - val_loss: 6.9916 - learning_rate: 5.0000e-04\nEpoch 30/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.8130 - val_loss: 7.1074 - learning_rate: 5.0000e-04\nEpoch 31/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.7652 - val_loss: 6.9294 - learning_rate: 5.0000e-04\nEpoch 32/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.7567 - val_loss: 6.9402 - learning_rate: 5.0000e-04\nEpoch 33/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.7191 - val_loss: 7.0075 - learning_rate: 5.0000e-04\nEpoch 34/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.6288 - val_loss: 7.1701 - learning_rate: 5.0000e-04\nEpoch 35/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.7127 - val_loss: 7.0379 - learning_rate: 5.0000e-04\nEpoch 36/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.6244 - val_loss: 6.9273 - learning_rate: 5.0000e-04\nEpoch 37/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.5725 - val_loss: 7.0386 - learning_rate: 5.0000e-04\nEpoch 38/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.6174 - val_loss: 6.9525 - learning_rate: 5.0000e-04\nEpoch 39/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.5216 - val_loss: 6.9709 - learning_rate: 5.0000e-04\nEpoch 40/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.4702 - val_loss: 7.0028 - learning_rate: 5.0000e-04\nEpoch 41/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.5286 - val_loss: 7.0140 - learning_rate: 5.0000e-04\nEpoch 42/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.3222 - val_loss: 6.9772 - learning_rate: 2.5000e-04\nEpoch 43/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.2087 - val_loss: 6.9310 - learning_rate: 2.5000e-04\nEpoch 44/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.0906 - val_loss: 6.9864 - learning_rate: 2.5000e-04\nEpoch 45/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.0684 - val_loss: 6.9819 - learning_rate: 2.5000e-04\nEpoch 46/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.9459 - val_loss: 6.9260 - learning_rate: 2.5000e-04\nEpoch 47/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.9808 - val_loss: 6.9169 - learning_rate: 2.5000e-04\nEpoch 48/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.9627 - val_loss: 6.9478 - learning_rate: 2.5000e-04\nEpoch 49/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.9321 - val_loss: 6.9716 - learning_rate: 2.5000e-04\nEpoch 50/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.8471 - val_loss: 6.9331 - learning_rate: 2.5000e-04\nEpoch 51/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.8729 - val_loss: 6.9076 - learning_rate: 2.5000e-04\nEpoch 52/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.8346 - val_loss: 6.9149 - learning_rate: 2.5000e-04\nEpoch 53/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.8116 - val_loss: 6.8949 - learning_rate: 2.5000e-04\nEpoch 54/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.8094 - val_loss: 6.8669 - learning_rate: 2.5000e-04\nEpoch 55/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.7482 - val_loss: 6.8343 - learning_rate: 2.5000e-04\nEpoch 56/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.7452 - val_loss: 6.8527 - learning_rate: 2.5000e-04\nEpoch 57/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.7241 - val_loss: 6.8352 - learning_rate: 2.5000e-04\nEpoch 58/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.6843 - val_loss: 6.8128 - learning_rate: 2.5000e-04\nEpoch 59/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.6868 - val_loss: 6.8211 - learning_rate: 2.5000e-04\nEpoch 60/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.6859 - val_loss: 6.8409 - learning_rate: 2.5000e-04\nEpoch 61/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.6488 - val_loss: 6.8189 - learning_rate: 2.5000e-04\nEpoch 62/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.6844 - val_loss: 6.8432 - learning_rate: 2.5000e-04\nEpoch 63/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.6267 - val_loss: 6.8289 - learning_rate: 2.5000e-04\nEpoch 64/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.5730 - val_loss: 6.8186 - learning_rate: 1.2500e-04\nEpoch 65/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.4723 - val_loss: 6.7811 - learning_rate: 1.2500e-04\nEpoch 66/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.4602 - val_loss: 6.8212 - learning_rate: 1.2500e-04\nEpoch 67/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.4184 - val_loss: 6.7832 - learning_rate: 1.2500e-04\nEpoch 68/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.4040 - val_loss: 6.7498 - learning_rate: 1.2500e-04\nEpoch 69/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.3611 - val_loss: 6.7555 - learning_rate: 1.2500e-04\nEpoch 70/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.3579 - val_loss: 6.7617 - learning_rate: 1.2500e-04\nEpoch 71/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.3250 - val_loss: 6.7166 - learning_rate: 1.2500e-04\nEpoch 72/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.2828 - val_loss: 6.6959 - learning_rate: 1.2500e-04\nEpoch 73/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.3162 - val_loss: 6.6502 - learning_rate: 1.2500e-04\nEpoch 74/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.2578 - val_loss: 6.7134 - learning_rate: 1.2500e-04\nEpoch 75/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.2257 - val_loss: 6.7277 - learning_rate: 1.2500e-04\nEpoch 76/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.2719 - val_loss: 6.7219 - learning_rate: 1.2500e-04\nEpoch 77/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.2627 - val_loss: 6.6707 - learning_rate: 1.2500e-04\nEpoch 78/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.2190 - val_loss: 6.7457 - learning_rate: 1.2500e-04\nEpoch 79/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.2415 - val_loss: 6.6900 - learning_rate: 6.2500e-05\nEpoch 80/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.1046 - val_loss: 6.7232 - learning_rate: 6.2500e-05\nEpoch 81/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.1195 - val_loss: 6.6658 - learning_rate: 6.2500e-05\nEpoch 82/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.1163 - val_loss: 6.7315 - learning_rate: 6.2500e-05\nEpoch 83/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 3.0746 - val_loss: 6.6830 - learning_rate: 6.2500e-05\n\u001b[1m493/493\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 6.5451\nTest Loss: 6.6501784324646\n\u001b[1m493/493\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\nRMSE: 4.140478955671943\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"from keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, BatchNormalization\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport numpy as np\nimport pandas as pd\n\n# Load and preprocess your data\ndf = pd.read_csv('/kaggle/input/main-dataset/Sampling_data.csv')\ndf['Drug Name'] = df['Drug Name'].astype('category').cat.codes\ndf['condition'] = df['condition'].astype('category').cat.codes\n\n# TF-IDF for the 'review' column\ntfidf = TfidfVectorizer(stop_words='english', max_features=200)\nreview_features = tfidf.fit_transform(df['review']).toarray()\nreview_df = pd.DataFrame(review_features, columns=tfidf.get_feature_names_out())\ndf = pd.concat([df, review_df], axis=1)\ndf.drop(columns=['review'], inplace=True)\n\n# Features and target\nfeatures = ['Drug Name', 'condition', 'usefulCount'] + list(review_df.columns)\ntarget = 'rating'\n\n# Split the data\nX = df[features].values\ny = df[target].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Feature Scaling\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Define and compile a simpler model\nmodel = Sequential()\nmodel.add(Dense(256, input_dim=X_train_scaled.shape[1], activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))  # Moderate dropout\nmodel.add(Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))  # Moderate dropout\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(1))  # Output layer for regression (rating prediction)\n\n# Compile model with AdamW optimizer\noptimizer = Adam(learning_rate=1e-4)\nmodel.compile(optimizer=optimizer, loss='mse')\n\n# Early stopping callback to prevent overfitting\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\n# Reduce learning rate on plateau\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n\n# Train the model\nhistory = model.fit(X_train_scaled, y_train, epochs=100, batch_size=64, validation_data=(X_test_scaled, y_test),\n                    verbose=1, callbacks=[early_stopping, reduce_lr])\n\n# Evaluate the model\nloss = model.evaluate(X_test_scaled, y_test)\nprint(f\"Test Loss: {loss}\")\n\n# Predict and calculate RMSE\ny_pred = model.predict(X_test_scaled)\nrmse = np.sqrt(((y_pred - y_test) ** 2).mean())\nprint(f\"RMSE: {rmse}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T21:35:47.197011Z","iopub.execute_input":"2025-01-30T21:35:47.197396Z","iopub.status.idle":"2025-01-30T21:39:04.262488Z","shell.execute_reply.started":"2025-01-30T21:35:47.197368Z","shell.execute_reply":"2025-01-30T21:39:04.261617Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 33.6399 - val_loss: 9.2386 - learning_rate: 1.0000e-04\nEpoch 2/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 9.7376 - val_loss: 7.9956 - learning_rate: 1.0000e-04\nEpoch 3/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 8.8017 - val_loss: 7.6202 - learning_rate: 1.0000e-04\nEpoch 4/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 8.3133 - val_loss: 7.3746 - learning_rate: 1.0000e-04\nEpoch 5/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.9621 - val_loss: 7.2423 - learning_rate: 1.0000e-04\nEpoch 6/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.7118 - val_loss: 7.1693 - learning_rate: 1.0000e-04\nEpoch 7/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.5234 - val_loss: 7.0961 - learning_rate: 1.0000e-04\nEpoch 8/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.3601 - val_loss: 6.9861 - learning_rate: 1.0000e-04\nEpoch 9/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.2073 - val_loss: 6.9589 - learning_rate: 1.0000e-04\nEpoch 10/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.0274 - val_loss: 6.9178 - learning_rate: 1.0000e-04\nEpoch 11/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.0995 - val_loss: 6.8470 - learning_rate: 1.0000e-04\nEpoch 12/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.9029 - val_loss: 6.8025 - learning_rate: 1.0000e-04\nEpoch 13/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.8097 - val_loss: 6.7870 - learning_rate: 1.0000e-04\nEpoch 14/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.7428 - val_loss: 6.7428 - learning_rate: 1.0000e-04\nEpoch 15/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.7068 - val_loss: 6.7190 - learning_rate: 1.0000e-04\nEpoch 16/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.5966 - val_loss: 6.7076 - learning_rate: 1.0000e-04\nEpoch 17/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.4053 - val_loss: 6.6971 - learning_rate: 1.0000e-04\nEpoch 18/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.4144 - val_loss: 6.6789 - learning_rate: 1.0000e-04\nEpoch 19/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.4629 - val_loss: 6.6399 - learning_rate: 1.0000e-04\nEpoch 20/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.3817 - val_loss: 6.6565 - learning_rate: 1.0000e-04\nEpoch 21/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.4142 - val_loss: 6.6130 - learning_rate: 1.0000e-04\nEpoch 22/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.2848 - val_loss: 6.5939 - learning_rate: 1.0000e-04\nEpoch 23/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.2466 - val_loss: 6.5880 - learning_rate: 1.0000e-04\nEpoch 24/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.1639 - val_loss: 6.5706 - learning_rate: 1.0000e-04\nEpoch 25/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.1009 - val_loss: 6.5545 - learning_rate: 1.0000e-04\nEpoch 26/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.1750 - val_loss: 6.5679 - learning_rate: 1.0000e-04\nEpoch 27/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.0894 - val_loss: 6.5618 - learning_rate: 1.0000e-04\nEpoch 28/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.9365 - val_loss: 6.4975 - learning_rate: 1.0000e-04\nEpoch 29/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.9032 - val_loss: 6.4706 - learning_rate: 1.0000e-04\nEpoch 30/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.8764 - val_loss: 6.4685 - learning_rate: 1.0000e-04\nEpoch 31/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.8316 - val_loss: 6.5439 - learning_rate: 1.0000e-04\nEpoch 32/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.8276 - val_loss: 6.4637 - learning_rate: 1.0000e-04\nEpoch 33/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.7271 - val_loss: 6.4389 - learning_rate: 1.0000e-04\nEpoch 34/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.6991 - val_loss: 6.4454 - learning_rate: 1.0000e-04\nEpoch 35/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.6576 - val_loss: 6.4710 - learning_rate: 1.0000e-04\nEpoch 36/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.6324 - val_loss: 6.3997 - learning_rate: 1.0000e-04\nEpoch 37/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.6423 - val_loss: 6.4211 - learning_rate: 1.0000e-04\nEpoch 38/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.5502 - val_loss: 6.4055 - learning_rate: 1.0000e-04\nEpoch 39/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.5657 - val_loss: 6.4219 - learning_rate: 1.0000e-04\nEpoch 40/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.4717 - val_loss: 6.3572 - learning_rate: 1.0000e-04\nEpoch 41/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.5119 - val_loss: 6.4142 - learning_rate: 1.0000e-04\nEpoch 42/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.4174 - val_loss: 6.3598 - learning_rate: 1.0000e-04\nEpoch 43/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.4238 - val_loss: 6.3835 - learning_rate: 1.0000e-04\nEpoch 44/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.3947 - val_loss: 6.3496 - learning_rate: 1.0000e-04\nEpoch 45/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.4103 - val_loss: 6.3311 - learning_rate: 1.0000e-04\nEpoch 46/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.3240 - val_loss: 6.3372 - learning_rate: 1.0000e-04\nEpoch 47/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.2785 - val_loss: 6.3231 - learning_rate: 1.0000e-04\nEpoch 48/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.2483 - val_loss: 6.3025 - learning_rate: 1.0000e-04\nEpoch 49/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.2295 - val_loss: 6.3150 - learning_rate: 1.0000e-04\nEpoch 50/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.2191 - val_loss: 6.3273 - learning_rate: 1.0000e-04\nEpoch 51/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.1678 - val_loss: 6.3495 - learning_rate: 1.0000e-04\nEpoch 52/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.1221 - val_loss: 6.3252 - learning_rate: 1.0000e-04\nEpoch 53/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.1486 - val_loss: 6.2974 - learning_rate: 1.0000e-04\nEpoch 54/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.0400 - val_loss: 6.2706 - learning_rate: 1.0000e-04\nEpoch 55/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.1204 - val_loss: 6.3089 - learning_rate: 1.0000e-04\nEpoch 56/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.0675 - val_loss: 6.2603 - learning_rate: 1.0000e-04\nEpoch 57/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.0045 - val_loss: 6.2434 - learning_rate: 1.0000e-04\nEpoch 58/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.9974 - val_loss: 6.2418 - learning_rate: 1.0000e-04\nEpoch 59/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.0344 - val_loss: 6.2266 - learning_rate: 1.0000e-04\nEpoch 60/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.9608 - val_loss: 6.2339 - learning_rate: 1.0000e-04\nEpoch 61/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.9202 - val_loss: 6.2148 - learning_rate: 1.0000e-04\nEpoch 62/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.9181 - val_loss: 6.2199 - learning_rate: 1.0000e-04\nEpoch 63/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.9023 - val_loss: 6.2411 - learning_rate: 1.0000e-04\nEpoch 64/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.8875 - val_loss: 6.2147 - learning_rate: 1.0000e-04\nEpoch 65/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.8397 - val_loss: 6.2378 - learning_rate: 1.0000e-04\nEpoch 66/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.8199 - val_loss: 6.2111 - learning_rate: 1.0000e-04\nEpoch 67/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.8315 - val_loss: 6.2093 - learning_rate: 1.0000e-04\nEpoch 68/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.7216 - val_loss: 6.2134 - learning_rate: 1.0000e-04\nEpoch 69/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.7852 - val_loss: 6.1864 - learning_rate: 1.0000e-04\nEpoch 70/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.7312 - val_loss: 6.2067 - learning_rate: 1.0000e-04\nEpoch 71/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.7591 - val_loss: 6.1919 - learning_rate: 1.0000e-04\nEpoch 72/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.7218 - val_loss: 6.1858 - learning_rate: 1.0000e-04\nEpoch 73/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.6947 - val_loss: 6.2068 - learning_rate: 1.0000e-04\nEpoch 74/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.6476 - val_loss: 6.1871 - learning_rate: 1.0000e-04\nEpoch 75/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.6666 - val_loss: 6.1952 - learning_rate: 1.0000e-04\nEpoch 76/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.6207 - val_loss: 6.1848 - learning_rate: 1.0000e-04\nEpoch 77/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.5909 - val_loss: 6.1851 - learning_rate: 1.0000e-04\nEpoch 78/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.5857 - val_loss: 6.1981 - learning_rate: 1.0000e-04\nEpoch 79/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.5977 - val_loss: 6.2021 - learning_rate: 1.0000e-04\nEpoch 80/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.4845 - val_loss: 6.1731 - learning_rate: 1.0000e-04\nEpoch 81/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.5811 - val_loss: 6.1984 - learning_rate: 1.0000e-04\nEpoch 82/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.5378 - val_loss: 6.2015 - learning_rate: 1.0000e-04\nEpoch 83/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.4560 - val_loss: 6.1641 - learning_rate: 1.0000e-04\nEpoch 84/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.5463 - val_loss: 6.1728 - learning_rate: 1.0000e-04\nEpoch 85/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.5014 - val_loss: 6.1933 - learning_rate: 1.0000e-04\nEpoch 86/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.5705 - val_loss: 6.1647 - learning_rate: 1.0000e-04\nEpoch 87/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.4422 - val_loss: 6.1794 - learning_rate: 1.0000e-04\nEpoch 88/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.3891 - val_loss: 6.1941 - learning_rate: 1.0000e-04\nEpoch 89/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.3794 - val_loss: 6.1338 - learning_rate: 5.0000e-05\nEpoch 90/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.3538 - val_loss: 6.1453 - learning_rate: 5.0000e-05\nEpoch 91/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.3227 - val_loss: 6.1380 - learning_rate: 5.0000e-05\nEpoch 92/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.3511 - val_loss: 6.1150 - learning_rate: 5.0000e-05\nEpoch 93/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.2372 - val_loss: 6.1156 - learning_rate: 5.0000e-05\nEpoch 94/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.3048 - val_loss: 6.1346 - learning_rate: 5.0000e-05\nEpoch 95/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.2981 - val_loss: 6.1463 - learning_rate: 5.0000e-05\nEpoch 96/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.3630 - val_loss: 6.1473 - learning_rate: 5.0000e-05\nEpoch 97/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.3363 - val_loss: 6.1433 - learning_rate: 5.0000e-05\nEpoch 98/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.2833 - val_loss: 6.1315 - learning_rate: 2.5000e-05\nEpoch 99/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.2134 - val_loss: 6.0926 - learning_rate: 2.5000e-05\nEpoch 100/100\n\u001b[1m986/986\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.2681 - val_loss: 6.1422 - learning_rate: 2.5000e-05\n\u001b[1m493/493\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5.9131\nTest Loss: 6.092586517333984\n\u001b[1m493/493\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\nRMSE: 4.019364040479545\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import pandas as pd\nimport nltk\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.preprocessing import LabelEncoder\nimport xgboost as xgb\nimport numpy as np\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\n# Load the dataset\ndf = pd.read_csv('/kaggle/input/datasss/Sampling_data.csv')\n\n# Clean column names to ensure consistency (strip spaces and adjust case)\ndf.columns = df.columns.str.strip()  # Remove any leading/trailing spaces\n\n# Apply sentiment analysis on the 'review' column\nnltk.download('vader_lexicon')\nsia = SentimentIntensityAnalyzer()\n\n# Apply sentiment analysis to 'review' column\ndf['sentiment_score'] = df['review'].apply(lambda x: sia.polarity_scores(str(x))['compound'])\n\n# Label Encoding for 'condition' column\nlabel_encoder = LabelEncoder()\ndf['condition_encoded'] = label_encoder.fit_transform(df['condition'])\n\n# Selecting the features and target variable\nX = df[['sentiment_score', 'condition_encoded', 'usefulCount']]  # Features: sentiment_score, condition_encoded, usefulCount\ny = df['rating']  # Target: rating\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Model training using XGBoost\nmodel = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=500, learning_rate=0.05, max_depth=7)\nmodel.fit(X_train, y_train)\n\n# Predicting on the test set\ny_pred = model.predict(X_test)\n\n# Evaluate the model using RMSE\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\n\n# Calculate MAE and R2\nmae = mean_absolute_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"R-squared (R2): {r2}\")\n\n# Track and display the training loss and validation loss (XGBoost doesn't provide direct loss, but we can monitor performance using evaluation metrics)\ntrain_loss = model.score(X_train, y_train)  # Model performance on training set\nval_loss = model.score(X_test, y_test)  # Model performance on test set\n\nprint(f\"Training Loss (R2): {train_loss}\")\nprint(f\"Validation Loss (R2): {val_loss}\")\n\n# Step 6: Compare Actual vs Predicted Ratings\nresults = pd.DataFrame({'Actual Rating': y_test, 'Predicted Rating': np.round(y_pred)})\nprint(results.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T11:26:56.862367Z","iopub.execute_input":"2025-02-01T11:26:56.862732Z","iopub.status.idle":"2025-02-01T11:27:59.419600Z","shell.execute_reply.started":"2025-02-01T11:26:56.862707Z","shell.execute_reply":"2025-02-01T11:27:59.418791Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n  warnings.warn(\"The twython library has not been installed. \"\n","output_type":"stream"},{"name":"stdout","text":"[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\nRoot Mean Squared Error (RMSE): 2.7593418605705406\nMean Absolute Error (MAE): 2.1871764125126143\nR-squared (R2): 0.25313282264695325\nTraining Loss (R2): 0.3740422824647931\nValidation Loss (R2): 0.25313282264695325\n       Actual Rating  Predicted Rating\n29406              5               6.0\n71698              7               8.0\n56929              9               9.0\n75201              7               8.0\n49098              8               7.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nprint(os.getcwd())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T04:36:40.800810Z","iopub.execute_input":"2025-01-31T04:36:40.801184Z","iopub.status.idle":"2025-01-31T04:36:40.805308Z","shell.execute_reply.started":"2025-01-31T04:36:40.801154Z","shell.execute_reply":"2025-01-31T04:36:40.804356Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin(token=\"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\")\nprint(\"done\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:06:17.908425Z","iopub.status.idle":"2025-01-31T03:06:17.908736Z","shell.execute_reply":"2025-01-31T03:06:17.908629Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install transformers torch\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T01:03:04.941913Z","iopub.execute_input":"2025-01-31T01:03:04.942218Z","iopub.status.idle":"2025-01-31T01:03:09.154955Z","shell.execute_reply.started":"2025-01-31T01:03:04.942192Z","shell.execute_reply":"2025-01-31T01:03:09.154072Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"import pandas as pd\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Step 1: Load the Data\ndata = pd.read_csv('/kaggle/input/datasss/Sampling_data.csv')\n\n# Step 2: Data Preprocessing\n# Handle missing values\ndata['review'].fillna('No review', inplace=True)\ndata['usefulCount'].fillna(0, inplace=True)\n\n# Label encoding for categorical features\nle = LabelEncoder()\ndata['Drug Name'] = le.fit_transform(data['Drug Name'])\ndata['condition'] = le.fit_transform(data['condition'])\n\n# Step 3: Advanced Text Vectorization (TF-IDF with n-grams)\ntfidf = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))  # Capture more context\nreview_features = tfidf.fit_transform(data['review']).toarray()\n\n# Step 4: Prepare Training Data\nX = pd.concat([data[['Drug Name', 'condition', 'usefulCount']], pd.DataFrame(review_features)], axis=1)\ny = data['rating']\n\n# Step 5: Train-Test Split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Step 6: LightGBM Model Training\ntrain_data = lgb.Dataset(X_train, label=y_train)\ntest_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n\n# Optimized Model Parameters\nparams = {\n    'objective': 'regression',\n    'metric': 'rmse',\n    'boosting_type': 'gbdt',\n    'num_leaves': 50,  # Increased complexity\n    'max_depth': 10,   # Deeper trees for better learning\n    'learning_rate': 0.03,  # Slightly slower but improves accuracy\n    'feature_fraction': 0.8,  # Helps generalization\n    'bagging_fraction': 0.9,\n    'bagging_freq': 5,\n    'lambda_l1': 0.1,  # L1 regularization\n    'lambda_l2': 0.1,  # L2 regularization\n    'min_data_in_leaf': 20,  # Avoids overfitting\n    'verbosity': -1\n}\n\n# Train the model with early stopping\ncallbacks = [lgb.early_stopping(stopping_rounds=100)]\nmodel = lgb.train(params, train_data, num_boost_round=2000, valid_sets=[test_data], callbacks=callbacks)\n\n# Step 7: Make Predictions\ny_pred = model.predict(X_test, num_iteration=model.best_iteration)\n\n# Step 8: Evaluate the Model\nmse = mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(mse)\nmae = mean_absolute_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\n# Displaying additional metrics\nprint(f\"Root Mean Squared Error (RMSE): {rmse}\")\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"R-squared (R2): {r2}\")\n\n# Step 9: Capture and Display Train and Validation Loss\n# Check the structure of best_score\nprint(model.best_score)\n\n# Assuming the 'rmse' is available under 'valid_0' (validation set)\ntrain_loss = model.best_score['training']['rmse'] if 'training' in model.best_score else None\nvalid_loss = model.best_score['valid_0']['rmse'] if 'valid_0' in model.best_score else None\n\nprint(f\"Training Loss (RMSE): {train_loss}\")\nprint(f\"Validation Loss (RMSE): {valid_loss}\")\n\n# Step 10: Compare Actual vs Predicted Ratings\nresults = pd.DataFrame({'Actual Rating': y_test, 'Predicted Rating': np.round(y_pred)})\nprint(results.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-01T12:18:11.937213Z","iopub.execute_input":"2025-02-01T12:18:11.937525Z","iopub.status.idle":"2025-02-01T12:28:45.112621Z","shell.execute_reply.started":"2025-02-01T12:18:11.937506Z","shell.execute_reply":"2025-02-01T12:28:45.111818Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-2-acc6b5ff582d>:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  data['review'].fillna('No review', inplace=True)\n<ipython-input-2-acc6b5ff582d>:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  data['usefulCount'].fillna(0, inplace=True)\n","output_type":"stream"},{"name":"stdout","text":"Training until validation scores don't improve for 100 rounds\nDid not meet early stopping. Best iteration is:\n[2000]\tvalid_0's rmse: 2.04561\nRoot Mean Squared Error (RMSE): 2.0456090522837886\nMean Absolute Error (MAE): 1.5590843614033991\nR-squared (R2): 0.5895335845699962\ndefaultdict(<class 'collections.OrderedDict'>, {'valid_0': OrderedDict([('rmse', 2.0456090522837886)])})\nTraining Loss (RMSE): None\nValidation Loss (RMSE): 2.0456090522837886\n       Actual Rating  Predicted Rating\n29406              5               4.0\n71698              7               7.0\n56929              9               8.0\n75201              7               8.0\n49098              8               8.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nimport numpy as np\nimport pandas as pd\nimport shutil\nimport matplotlib.pyplot as plt\nfrom IPython.display import FileLink\n\n# Load dataset\ndf = pd.read_csv('/kaggle/input/488-data/Sampling_data.csv')  # Update path if needed\n\n# Handle missing values\ndf['review'] = df['review'].fillna('')\ndf['Drug Name'] = df['Drug Name'].fillna('Unknown')\ndf['condition'] = df['condition'].fillna('Unknown')\ndf['usefulCount'] = df['usefulCount'].fillna(0)\n\n# Tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\nclass DrugReviewDataset(Dataset):\n    def __init__(self, reviews, labels, tokenizer, max_len):\n        self.reviews = reviews\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.reviews)\n\n    def __getitem__(self, item):\n        text = str(self.reviews[item])\n        label = self.labels[item]\n\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.float)\n        }\n\n# Concatenate additional features with the review text\ndf['combined_text'] = df['Drug Name'] + \" \" + df['condition'] + \" \" + df['review'] + \" UsefulCount: \" + df['usefulCount'].astype(str)\n\n# Define max token length\nmax_len = 128  \nreviews = df['combined_text'].values\nlabels = df['rating'].values\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(reviews, labels, test_size=0.2, random_state=42)\n\n# Create dataset\ndataset_train = DrugReviewDataset(X_train, y_train, tokenizer, max_len)\ndataset_test = DrugReviewDataset(X_test, y_test, tokenizer, max_len)\ntrain_loader = DataLoader(dataset_train, batch_size=16, shuffle=True)\ntest_loader = DataLoader(dataset_test, batch_size=16)\n\n# Load BERT model for regression\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)\n\n# Optimizer\noptimizer = AdamW(model.parameters(), lr=1e-5)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\n# Training loop\nepochs = 15\ntrain_losses = []  # Store losses for visualization\n\nfor epoch in range(epochs):\n    model.train()\n    total_train_loss = 0\n    \n    for batch in train_loader:\n        optimizer.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        total_train_loss += loss.item()\n\n        loss.backward()\n        optimizer.step()\n    \n    avg_train_loss = total_train_loss / len(train_loader)\n    train_losses.append(avg_train_loss)\n    print(f'Epoch {epoch + 1}/{epochs}, Training Loss: {avg_train_loss:.4f}')\n\n# Plot Training Loss\nplt.figure(figsize=(8, 5))\nplt.plot(range(1, epochs + 1), train_losses, marker='o', linestyle='-', color='b', label=\"Training Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training Loss Curve\")\nplt.legend()\nplt.grid()\nplt.savefig(\"/kaggle/working/training_loss.png\")  # Save the plot\nplt.show()\n\n# Evaluation\nmodel.eval()\npredictions, true_labels = [], []\n\nfor batch in test_loader:\n    input_ids = batch['input_ids'].to(device)\n    attention_mask = batch['attention_mask'].to(device)\n    labels = batch['labels'].to(device)\n\n    with torch.no_grad():\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n\n    predictions.append(logits.cpu().numpy())\n    true_labels.append(labels.cpu().numpy())\n\npredictions = np.concatenate(predictions).flatten()\ntrue_labels = np.concatenate(true_labels)\n\n# Compute Evaluation Metrics\nrmse = np.sqrt(mean_squared_error(true_labels, predictions))  \nmae = mean_absolute_error(true_labels, predictions)\nr2 = r2_score(true_labels, predictions)\n\n# Save evaluation metrics to a text file\nevaluation_results = f\"RMSE: {rmse:.4f}\\nMAE: {mae:.4f}\\nRÂ² Score: {r2:.4f}\\n\"\n\nwith open(\"/kaggle/working/evaluation_results.txt\", \"w\") as f:\n    f.write(evaluation_results)\n\nprint(\"Evaluation results saved successfully.\")\nprint(evaluation_results)\n\n# Save the trained model\nsave_directory = \"/kaggle/working/new_drug_rating_model\"\nmodel.save_pretrained(save_directory)\ntokenizer.save_pretrained(save_directory)\n\nshutil.make_archive(save_directory, 'zip', save_directory)\nprint(\"Download the model from the link below:\")\nFileLink(f\"{save_directory}.zip\")\n\n# Provide download links for evaluation results & training loss plot\nprint(\"Download the evaluation results from the link below:\")\nFileLink(\"/kaggle/working/evaluation_results.txt\")\n\nprint(\"Download the training loss plot from the link below:\")\nFileLink(\"/kaggle/working/training_loss.png\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"![image.png](attachment:d7dbb589-14a0-4e93-a7e2-cd239ce53115.png)\n![image.png](attachment:4c59f6e0-82a5-4417-9475-ff3829f024c2.png)","metadata":{},"attachments":{"d7dbb589-14a0-4e93-a7e2-cd239ce53115.png":{"image/png":"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"},"4c59f6e0-82a5-4417-9475-ff3829f024c2.png":{"image/png":"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"}}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}